

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Data Structures &#8212; SmartSim 0.6.2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom_tab_style.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'sr_data_structures';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="DataSet Conversions" href="sr_dataset_conversions.html" />
    <link rel="prev" title="Fortran" href="sr_fortran_walkthrough.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
  
    <p class="title logo__title">SmartSim 0.6.2 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="versions.html">Versions</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation_instructions/basic.html">Basic Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation_instructions/platform.html">Installation on specific platforms</a></li>







<li class="toctree-l1"><a class="reference internal" href="contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="smartsim_zoo.html">Contributing Examples</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="tutorials/getting_started/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/online_analysis/lattice/online_analysis.html">Online Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorials/ml_inference/Inference-in-SmartSim.html">Online Inference</a></li>

<li class="toctree-l1"><a class="reference internal" href="tutorials/ml_training/surrogate/train_surrogate.html">Online Training</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SmartSim</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="experiment.html">Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="orchestrator.html">Orchestrator</a></li>
<li class="toctree-l1"><a class="reference internal" href="launchers.html">Launchers</a></li>
<li class="toctree-l1"><a class="reference internal" href="ml_features.html">ML Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/smartsim_api.html">SmartSim API</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SmartRedis</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="smartredis.html">SmartRedis</a></li>
<li class="toctree-l1"><a class="reference internal" href="sr_integration.html">Integrating into a Simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="sr_python_walkthrough.html">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="sr_cpp_walkthrough.html">C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="sr_fortran_walkthrough.html">Fortran</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Data Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="sr_dataset_conversions.html">DataSet Conversions</a></li>
<li class="toctree-l1"><a class="reference internal" href="sr_runtime.html">Runtime Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="sr_advanced_topics.html">Advanced Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/smartredis_api.html">SmartRedis API</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SmartDashboard</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="smartdashboard.html">SmartDashboard</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="code_of_conduct.html">Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="developer.html">Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="testing.html">Testing</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/CrayLabs/SmartSim" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/CrayLabs/SmartSim/issues/new?title=Issue%20on%20page%20%2Fsr_data_structures.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/sr_data_structures.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Data Structures</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor">Tensor</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sending">Sending</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#retrieving">Retrieving</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset">Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#build-and-send-a-dataset">Build and Send a DataSet</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#retrieving-a-dataset">Retrieving a DataSet</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aggregating">Aggregating</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model">Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#build-and-send-a-model">Build and Send a Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Retrieving</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#executing">Executing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#support-on-systems-with-multiple-gpus">Support on Systems with Multiple GPUs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#script">Script</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Sending</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Retrieving</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Executing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Support on Systems with Multiple GPUs</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="data-structures">
<h1>Data Structures<a class="headerlink" href="#data-structures" title="Permalink to this heading">#</a></h1>
<p>SmartSim defines primary three data structures designed for use within backend databases:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Tensor</span></code> : represents an n-dimensional array of values.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Model</span></code> : represents a computational ML model for one of the supported backend frameworks.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Script</span></code> : represents a TorchScript program.</p></li>
</ul>
<p>In addition, SmartRedis defines a data
structure named <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> that enables a user to manage a group of tensors
and associated metadata in-memory. In this section, we will provide an explanation
of the SmartRedis API used to interact with these four data structures,
along with relevant insights on performance and best practices.</p>
<p>We illustrate concepts and capabilities of the Python
and C++ SmartRedis APIs. The C and Fortran function signatures closely
mirror the C++ API, and for brevity, we won’t delve
into them. For full discussion of the C and Fortran APIs,
please refer to their respective documentation pages.</p>
<section id="tensor">
<span id="data-structures-tensor"></span><h2>Tensor<a class="headerlink" href="#tensor" title="Permalink to this heading">#</a></h2>
<p>An n-dimensional tensor is used by RedisAI to store and
manipulate numerical data. SmartRedis provides functions to
put a key and tensor pair into the backend database and retrieve
a tensor associated with a key from the database.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When utilizing SmartRedis with SmartSim ensemble functionality,
the name provided by the user may be manipulated before placement
in or retrieval from the database in order to avoid key collisions
between ensemble members.  Therefore, when using SmartSim ensemble
functionality, retrieval of a tensor using the Redis command line
interface (CLI) will require adapting the tensor name.</p>
</div>
<section id="sending">
<h3>Sending<a class="headerlink" href="#sending" title="Permalink to this heading">#</a></h3>
<p>In Python, the <code class="docutils literal notranslate"><span class="pre">Client</span></code> infers the type and dimensions of the
tensor from the NumPy array data structure, and as a result,
only the name and NumPy array are needed to place a key and tensor
pair in the database.  Currently, only NumPy arrays
are supported as inputs and outputs of Python <code class="docutils literal notranslate"><span class="pre">Client</span></code>
tensor functions.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Python put_tensor() interface</span>
<span class="n">put_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>In the compiled clients, more information is needed to inform the
<code class="docutils literal notranslate"><span class="pre">Client</span></code> about the tensor properties.  In the C++ API,
the dimensions of the tensor are provided via a
<code class="docutils literal notranslate"><span class="pre">std::vector&lt;size_t&gt;</span></code> input parameter.  Additionally, the type
associated with the tensor data (e.g. <code class="docutils literal notranslate"><span class="pre">double</span></code>, <code class="docutils literal notranslate"><span class="pre">float</span></code>)
is specified with a <code class="docutils literal notranslate"><span class="pre">SRTensorType</span></code> enum.
Finally, the <code class="docutils literal notranslate"><span class="pre">Client</span></code> must know the memory
layout of the provided tensor data in order to traverse the
tensor data to generate a tensor data buffer. In C++, tensor
data can either be in a contiguous memory layout or in a nested,
non-contiguous memory layout (i.e. nested pointer arrays to
underlying allocated memory). The memory layout of the tensor
data to place in the database is specified
with a <code class="docutils literal notranslate"><span class="pre">SRMemoryLayout</span></code> enum input parameter.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// C++ put_tensor interface</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">put_tensor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">name</span><span class="p">,</span>
<span class="w">                </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">,</span>
<span class="w">                </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">dims</span><span class="p">,</span>
<span class="w">                </span><span class="k">const</span><span class="w"> </span><span class="n">SRTensorType</span><span class="w"> </span><span class="n">type</span><span class="p">,</span>
<span class="w">                </span><span class="k">const</span><span class="w"> </span><span class="n">SRMemoryLayout</span><span class="w"> </span><span class="n">mem_layout</span><span class="p">);</span>
</pre></div>
</div>
<p>C and Fortran have similar function prototypes compared
to the C++ client, except the C client uses only C data
types and the Fortran client does not require the
specification of the tensor memory layout because it is
assumed that Fortran array memory is allocated in a column-major,
contiguous manner.</p>
</section>
<section id="retrieving">
<h3>Retrieving<a class="headerlink" href="#retrieving" title="Permalink to this heading">#</a></h3>
<p>The C++, C, and Fortran clients provide two methods for retrieving
tensors from the backend database. The first method is referred to
as <em>unpacking</em> a tensor.  When a tensor is retrieved via
<code class="docutils literal notranslate"><span class="pre">unpack_tensor()</span></code>, the memory space to store the retrieved
tensor data is provided by the user. This has the advantage
of giving the user the ability to manage the scope of the retrieved
tensor allocated memory and reuse application memory.</p>
<p>The C++ function signature for <code class="docutils literal notranslate"><span class="pre">unpack_tensor()</span></code> is shown below.
In the case of <code class="docutils literal notranslate"><span class="pre">unpack_tensor()</span></code> the parameters <code class="docutils literal notranslate"><span class="pre">dims</span></code>,
<code class="docutils literal notranslate"><span class="pre">type</span></code>, and <code class="docutils literal notranslate"><span class="pre">mem_layout</span></code> are used to specify the
characteristics of the user-provided memory space.
The type and dimensions are compared to the tensor that is retrieved
from the database, and if the type does not match or if the
allocated space is insufficient,
an error will be thrown.  Otherwise, the memory space pointed
to by the <code class="docutils literal notranslate"><span class="pre">data</span></code> pointer will be filled consistent with the
specified memory layout.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// C++ unpack_tensor() interface</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">unpack_tensor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">name</span><span class="p">,</span>
<span class="w">                   </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">,</span>
<span class="w">                   </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">dims</span><span class="p">,</span>
<span class="w">                   </span><span class="k">const</span><span class="w"> </span><span class="n">SRTensorType</span><span class="w"> </span><span class="n">type</span><span class="p">,</span>
<span class="w">                   </span><span class="k">const</span><span class="w"> </span><span class="n">SRMemoryLayout</span><span class="w"> </span><span class="n">mem_layout</span><span class="p">);</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using <code class="docutils literal notranslate"><span class="pre">unpack_tensor()</span></code> with a user-provided
<code class="docutils literal notranslate"><span class="pre">SRMemLayoutContiguous</span></code> memory space,
the provided dimensions should be a
<code class="docutils literal notranslate"><span class="pre">std::vector&lt;size_t&gt;</span></code> with a single value
equal the total number of allocated
values in the memory space, not the expected
dimensions of the retrieved tensor.</p>
</div>
<p>The other option for retrieving a tensor with the
C++, C, and Fortran clients is <code class="docutils literal notranslate"><span class="pre">get_tensor()</span></code>.
With <code class="docutils literal notranslate"><span class="pre">get_tensor()</span></code>, it is assumed that the user does not
know the dimensions or type of the tensor, and as a result, the
<code class="docutils literal notranslate"><span class="pre">Client</span></code> allocates and manages memory necessary for the retrieved
tensor data.  The C++ function signature for <code class="docutils literal notranslate"><span class="pre">get_tensor()</span></code> is shown
below.  Note that a pointer to the newly allocated data, tensor
dimensions, and tensor type are returned to the user via
modifying referenced variables that the user declares before the
<code class="docutils literal notranslate"><span class="pre">get_tensor()</span></code> call.  This is done to provide a similar
experience across the C++, C, and Fortran clients.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// C++ get_tensor interface</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">get_tensor</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">name</span><span class="p">,</span>
<span class="w">                </span><span class="kt">void</span><span class="o">*&amp;</span><span class="w"> </span><span class="n">data</span><span class="p">,</span>
<span class="w">                </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">size_t</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">dims</span><span class="p">,</span>
<span class="w">                </span><span class="n">SRTensorType</span><span class="o">&amp;</span><span class="w"> </span><span class="n">type</span><span class="p">,</span>
<span class="w">                </span><span class="k">const</span><span class="w"> </span><span class="n">SRMemoryLayout</span><span class="w"> </span><span class="n">mem_layout</span><span class="p">);</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Memory allocated by C++, C, and Fortran
<code class="docutils literal notranslate"><span class="pre">Client</span></code> during a <code class="docutils literal notranslate"><span class="pre">get_tensor()</span></code>
call will be valid and not freed until the <code class="docutils literal notranslate"><span class="pre">Client</span></code>
object is destroyed.  Therefore, if the type and dimensions
of the tensor are known, it is recommended that
<code class="docutils literal notranslate"><span class="pre">unpack_tensor()</span></code> is used in memory-constrained situations.</p>
</div>
<p>The Python client currently only offers a <code class="docutils literal notranslate"><span class="pre">get_tensor()</span></code> option for
retrieving tensors.  In this methodology, a NumPy array is returned
to the user, and the only required input to the function is the
name of the tensor to retrieve because its type and dimensions
are embedded in the NumPy array object. The Python interface for
<code class="docutils literal notranslate"><span class="pre">get_tensor()</span></code> is shown below.  In the Python implementation of
<code class="docutils literal notranslate"><span class="pre">get_tensor()</span></code>, the memory associated with the retrieved tensor
will be freed when the NumPy array goes out of scope or is deleted.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Python get_tensor() interface</span>
<span class="n">get_tensor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
</pre></div>
</div>
<p>Note that all of the client <code class="docutils literal notranslate"><span class="pre">get_tensor()</span></code> functions will internally
modify the provided tensor name if the client is being used with
SmartSim ensemble capabilities.</p>
</section>
</section>
<section id="dataset">
<span id="data-structures-dataset"></span><h2>Dataset<a class="headerlink" href="#dataset" title="Permalink to this heading">#</a></h2>
<p>When dealing with multi-modal data or complex data sets,
one may have different types of tensors (e.g., images, text embeddings,
numerical data) and metadata for each data point. Grouping them into a
collection represents each data point as a cohesive unit.
The <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> data structure provides this functionality to stage tensors and metadata
in-memory via the <code class="docutils literal notranslate"><span class="pre">DataSet</span> <span class="pre">API</span></code>. After the creation of a
<code class="docutils literal notranslate"><span class="pre">DataSet</span></code> object, the grouped data can be efficiently stored in the backend database
by the <code class="docutils literal notranslate"><span class="pre">Client</span> <span class="pre">API</span></code> and subsequently retrieved using the assigned <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> name.
In the upcoming sections, we outline the process of building, sending, and retrieving a <code class="docutils literal notranslate"><span class="pre">DataSet</span></code>.</p>
<p>Listed below are the supported tensor and metadata types.</p>
<table class="table table-center" id="id6">
<caption><span class="caption-text">Supported Data Types</span><a class="headerlink" href="#id6" title="Permalink to this table">#</a></caption>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Data Type</p></th>
<th class="head"><p>Tensor (n-dim arrays)</p></th>
<th class="head"><p>Metadata (1-D arrays)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Float</p></td>
<td><p>X</p></td>
<td><p>X</p></td>
</tr>
<tr class="row-odd"><td><p>Double</p></td>
<td><p>X</p></td>
<td><p>X</p></td>
</tr>
<tr class="row-even"><td><p>Int64</p></td>
<td><p>X</p></td>
<td><p>X</p></td>
</tr>
<tr class="row-odd"><td><p>Int32</p></td>
<td><p>X</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>Int16</p></td>
<td><p>X</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>Int8</p></td>
<td><p>X</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>UInt64</p></td>
<td></td>
<td><p>X</p></td>
</tr>
<tr class="row-odd"><td><p>UInt32</p></td>
<td></td>
<td><p>X</p></td>
</tr>
<tr class="row-even"><td><p>UInt16</p></td>
<td><p>X</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p>UInt8</p></td>
<td><p>X</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p>String</p></td>
<td></td>
<td><p>X</p></td>
</tr>
</tbody>
</table>
<section id="build-and-send-a-dataset">
<h3>Build and Send a DataSet<a class="headerlink" href="#build-and-send-a-dataset" title="Permalink to this heading">#</a></h3>
<p>When building a <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> object in-memory,
a user can group various combinations of tensors and metadata that
constrain to the supported data types in the table above. To illustrate,
tensors can be inserted into a <code class="docutils literal notranslate"><span class="pre">dataset</span></code> object via the <code class="docutils literal notranslate"><span class="pre">Dataset.add_tensor()</span></code> method.
The SmartRedis DataSet API functions
are available in C, C++, Python, and Fortran. The <code class="docutils literal notranslate"><span class="pre">DataSet.add_tensor()</span></code> function,
operates independently of the database and solely
maintains the dataset object. Storing the dataset in the backend
database is done via the Client API <code class="docutils literal notranslate"><span class="pre">put_dataset()</span></code> method.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">DataSet.add_tensor()</span></code> function copies user-provided
tensor data; this prevents potential issues arising from the user’s
data being cleared or deallocated. Any additional memory allocated
for this purpose will be released when the DataSet object is destroyed.</p>
</div>
<p>Metadata can be added to an in-memory <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> object with the
<code class="docutils literal notranslate"><span class="pre">DataSet.add_meta_scalar()</span></code> and <code class="docutils literal notranslate"><span class="pre">DataSet.add_meta_string()</span></code>
functions. Methods exist for adding scalar metadata (e.g., double) and string metadata.
For both functions, the first input
parameter is the name of the metadata field.
The field name serves as an internal identifier within the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code>
for grouped metadata values. It’s used to retrieve metadata in the future.
Since it’s an internal identifier, users don’t need to be concerned
about conflicts with keys in the database. In other words, multiple
<code class="docutils literal notranslate"><span class="pre">DataSet</span></code> objects can use the same metadata field names without causing
issues because these names are managed within the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> and won’t
interfere with external database keys. The C++ interface for adding
metadata is shown below:</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// C++ add_meta_scalar() interface</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">add_meta_scalar</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">name</span><span class="p">,</span>
<span class="w">                     </span><span class="k">const</span><span class="w"> </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">data</span><span class="p">,</span>
<span class="w">                     </span><span class="k">const</span><span class="w"> </span><span class="n">SRMetaDataType</span><span class="w"> </span><span class="n">type</span><span class="p">);</span>

<span class="c1">// C++ add_meta_string() interface</span>
<span class="kt">void</span><span class="w"> </span><span class="nf">add_meta_string</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">name</span><span class="p">,</span>
<span class="w">                     </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">data</span><span class="p">);</span>
</pre></div>
</div>
<p>When adding a scalar or string metadata value, the value
is copied by the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code>, and as a result, the user
does not need to ensure that the metadata values provided
are still in-memory. In other words,
the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> handles the memory management of these metadata values,
and you don’t need to retain or manage the original copies separately
once they have been included in the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> object.
Additionally, multiple metadata values can be added to a
single field name, and the default behavior is to append the value to the
field name (creating the field if not already present). This behavior allows the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> metadata
to function like one-dimensional arrays.</p>
<p>Also, note that in the above C++ example,
the metadata scalar type must be specified with a
<code class="docutils literal notranslate"><span class="pre">SRMetaDataType</span></code> enum value; similar
requirements exist for C and Fortran <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> implementations.</p>
<p>Finally, the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> object is sent to the database using the
<code class="docutils literal notranslate"><span class="pre">Client.put_dataset()</span></code> function, which is uniform across all clients.
To emphasize once more, all interactions with the backend database are handle by
the Client API, not the DataSet API.</p>
</section>
<section id="retrieving-a-dataset">
<h3>Retrieving a DataSet<a class="headerlink" href="#retrieving-a-dataset" title="Permalink to this heading">#</a></h3>
<p>In all clients, the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> is retrieved with a single
function call to <code class="docutils literal notranslate"><span class="pre">Client.get_dataset()</span></code>, which requires
only the name of the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> (i.e. the name used
in the constructor of the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> when it was
built and placed in the database by the Client API). <code class="docutils literal notranslate"><span class="pre">Client.get_dataset()</span></code>
returns to the user a <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> object (in C, a pointer to a
<code class="docutils literal notranslate"><span class="pre">DataSet</span></code> object) from the database that is used to access all of the
dataset tensors and metadata.</p>
<p>The functions for retrieving tensors from an in-memory <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> object
are identical to the functions provided by <code class="docutils literal notranslate"><span class="pre">Client</span></code>,
and the same return values and memory management
paradigm is followed. As a result, please refer to
the previous section for details on tensor retrieve
function calls.</p>
<p>There are four functions for retrieving metadata information from a <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> object in-memory:
<code class="docutils literal notranslate"><span class="pre">get_meta_scalars()</span></code>, <code class="docutils literal notranslate"><span class="pre">get_meta_strings()</span></code>, <code class="docutils literal notranslate"><span class="pre">get_metadata_field_names()</span></code>
and <code class="docutils literal notranslate"><span class="pre">get_metadata_field_type()</span></code>. As the names suggest, the <code class="docutils literal notranslate"><span class="pre">get_meta_scalars()</span></code> function
is used for retrieving numerical metadata values, while the <code class="docutils literal notranslate"><span class="pre">get_meta_strings()</span></code> function
is for retrieving metadata string values. The <code class="docutils literal notranslate"><span class="pre">get_metadata_field_names()</span></code> function
retrieves a list of all metadata field names in the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> object. Lastly,
the <code class="docutils literal notranslate"><span class="pre">get_metadata_field_type()</span></code> function returns the type (scalar or string) of the metadata
attached to the specified field name. The metadata retrieval function prototypes
vary across the clients based on programming language constraints,
and as a result, please refer to the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> API documentation
for a description of input parameters and memory management. It is
important to note, however, that all functions require the name of the
metadata field to be retrieved. This name is the same name that
was used when constructing the metadata field with
<code class="docutils literal notranslate"><span class="pre">add_meta_scalar()</span></code> and <code class="docutils literal notranslate"><span class="pre">add_meta_string()</span></code> functions.</p>
</section>
<section id="aggregating">
<h3>Aggregating<a class="headerlink" href="#aggregating" title="Permalink to this heading">#</a></h3>
<p>SmartRedis also supports an advanced API for working with aggregate
lists of DataSets; details may be found <a class="reference internal" href="sr_advanced_topics.html#advanced-topics-dataset-aggregation"><span class="std std-ref">here</span></a>.</p>
</section>
</section>
<section id="model">
<span id="data-structures-model"></span><h2>Model<a class="headerlink" href="#model" title="Permalink to this heading">#</a></h2>
<p>Like tensors, the RedisAI model data structure is exposed to users
through <code class="docutils literal notranslate"><span class="pre">Client</span></code> function calls to place a model in the database,
retrieve a model from the database, and run a model.  Note that
RedisAI supports PyTorch, TensorFlow, TensorFlow Lite, and ONNX
backends, and specifying the backend to be used is done
through the <code class="docutils literal notranslate"><span class="pre">Client</span></code> function calls.</p>
<section id="build-and-send-a-model">
<h3>Build and Send a Model<a class="headerlink" href="#build-and-send-a-model" title="Permalink to this heading">#</a></h3>
<p>A model is placed in the database through the <code class="docutils literal notranslate"><span class="pre">Client.set_model()</span></code>
function.  While data types may differ, the function parameters
are uniform across all SmartRedis clients, and as an example, the C++
<code class="docutils literal notranslate"><span class="pre">set_model()</span></code> function is shown below.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="cp"># C++ set_model interface</span>
<span class="kt">void</span><span class="w"> </span><span class="n">set_model</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">name</span><span class="p">,</span>
<span class="w">               </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string_view</span><span class="o">&amp;</span><span class="w"> </span><span class="n">model</span><span class="p">,</span>
<span class="w">               </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">backend</span><span class="p">,</span>
<span class="w">               </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span>
<span class="w">               </span><span class="kt">int</span><span class="w"> </span><span class="n">batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">               </span><span class="kt">int</span><span class="w"> </span><span class="n">min_batch_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">               </span><span class="kt">int</span><span class="w"> </span><span class="n">min_batch_timeout</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">               </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">tag</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;&quot;</span><span class="p">,</span>
<span class="w">               </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">inputs</span>
<span class="w">                   </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span><span class="p">(),</span>
<span class="w">               </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;&amp;</span><span class="w"> </span><span class="n">outputs</span>
<span class="w">                   </span><span class="o">=</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span><span class="p">());</span>
</pre></div>
</div>
<p>All of the parameters in <code class="docutils literal notranslate"><span class="pre">set_model()</span></code> follow the RedisAI
API for the the RedisAI <code class="docutils literal notranslate"><span class="pre">AI.MODELSET</span></code> command, and as a result,
the reader is encouraged to read the SmartRedis client code
documentation or the RedisAI documentation for a description
of each parameter.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>With a clustered Redis backend configuration, <code class="docutils literal notranslate"><span class="pre">Client.set_model()</span></code>
will distribute a copy of the model to each database node in the
cluster.  As a result, the model that has been
placed in the cluster with <code class="docutils literal notranslate"><span class="pre">Client.set_model()</span></code>
will not be addressable directly with the Redis CLI because
of key manipulation that is required to accomplish
this distribution.  Despite the internal key
manipulation, models in a clustered Redis backend that have been
set through the SmartRedis <code class="docutils literal notranslate"><span class="pre">Client</span></code> can be accessed
and run through the SmartRedis <code class="docutils literal notranslate"><span class="pre">Client</span></code> API
using the name provided to <code class="docutils literal notranslate"><span class="pre">set_model()</span></code>.  The user
does not need any knowledge of the cluster model distribution
to perform RedisAI model actions.  Moreover,
a model set by one SmartRedis client (e.g. Python) on a Redis
cluster is addressable with the same name through another
client (e.g. C++).</p>
</div>
<p>Finally, there is a similar function in each client,
<code class="docutils literal notranslate"><span class="pre">Client.set_model_from_file()</span></code>, that will read a
model from file and set it in the database.</p>
</section>
<section id="id1">
<h3>Retrieving<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h3>
<p>A model can be retrieved from the database using the
<code class="docutils literal notranslate"><span class="pre">Client.get_model()</span></code> function.  While the return
type varies between languages, only the model name
that was used with <code class="docutils literal notranslate"><span class="pre">Client.set_model()</span></code> is needed
to reference the model in the database.  Note that
in a clustered Redis backend configuration, only one copy of the
model is returned to the user.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">Client.get_model()</span></code> will allocate memory to retrieve
the model from the database, and this memory will not
be freed until the Client object is destroyed.</p>
</div>
</section>
<section id="executing">
<h3>Executing<a class="headerlink" href="#executing" title="Permalink to this heading">#</a></h3>
<p>A model can be executed using the <code class="docutils literal notranslate"><span class="pre">Client.run_model()</span></code> function.
The only required inputs to execute a model are the model name,
a list of input tensor names, and a list of output tensor names.
If using a clustered Redis backend configuration, a copy of the model
referenced by the provided name will be chosen based on data locality.
It is worth noting that the names of input and output tensors will be
altered with ensemble member identifications if the SmartSim
ensemble compatibility features are used.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>DataSet tensors can be used as <code class="docutils literal notranslate"><span class="pre">run_model()</span></code> input tensors,
but the name provided to <code class="docutils literal notranslate"><span class="pre">run_model()</span></code> must be prefixed with
the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> name in the pattern <code class="docutils literal notranslate"><span class="pre">{dataset_name}.tensor_name</span></code>.</p>
</div>
</section>
<section id="support-on-systems-with-multiple-gpus">
<h3>Support on Systems with Multiple GPUs<a class="headerlink" href="#support-on-systems-with-multiple-gpus" title="Permalink to this heading">#</a></h3>
<p>SmartRedis has special support for models on systems with multiple GPUs.
On these systems, the model can be set via the <code class="docutils literal notranslate"><span class="pre">Client.set_model_multigpu()</span></code>
function, which differs from the <code class="docutils literal notranslate"><span class="pre">Client.set_model()</span></code> function only in that
(1) there is no need to specify a device (GPU is implicit) and (2) the caller
must supply the index of the first GPU to use with the model and the total
number of GPUs on the system’s nodes to use with the model. The function will
then create separate copies of the model for each GPU by appending <code class="docutils literal notranslate"><span class="pre">.GPU:n</span></code>
to the supplied name, where <code class="docutils literal notranslate"><span class="pre">n</span></code> is a number from <code class="docutils literal notranslate"><span class="pre">first_gpu</span></code> to
<code class="docutils literal notranslate"><span class="pre">first_gpu</span> <span class="pre">+</span> <span class="pre">num_gpus</span> <span class="pre">-</span> <span class="pre">1</span></code>, inclusive.</p>
<p>Executing models on systems with multiple GPUs may be done via the
<code class="docutils literal notranslate"><span class="pre">Client.run_model_multigpu()</span></code> function. This method parallels
<code class="docutils literal notranslate"><span class="pre">Client.run_model()</span></code> except that it requires three additional parameters:
the first GPU to use for execution, the number of GPUs to use for execution,
and an offset for the currently executing thread or image. The model execution
is then dispatched to the copy of the script on the GPU corresponding to
<code class="docutils literal notranslate"><span class="pre">first_gpu</span></code> plus the offset modulo <code class="docutils literal notranslate"><span class="pre">num_gpus</span></code>.  The image offset may
be an MPI rank, or a thread ID, or any other indexing scheme.</p>
<p>Finally, models stored for multiple GPUs may be deleted via the
<code class="docutils literal notranslate"><span class="pre">Client.delete_model_multigpu()</span></code> function. This method parallels
<code class="docutils literal notranslate"><span class="pre">Client.delete_model()</span></code> except that it requires two additional parameters:
the first GPU and the number of GPUs that the model was stored with. This
function will delete all the extra copies of the model that were stored
via <code class="docutils literal notranslate"><span class="pre">Client.set_model_multigpu()</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In order for a model to be executed via <code class="docutils literal notranslate"><span class="pre">Client.run_model_multigpu()</span></code>,
or deleted via <code class="docutils literal notranslate"><span class="pre">Client.delete_model_multigpu()</span></code>,
it must have been set via <code class="docutils literal notranslate"><span class="pre">Client.set_model_multigpu()</span></code>. The
<code class="docutils literal notranslate"><span class="pre">first_gpu</span></code> and <code class="docutils literal notranslate"><span class="pre">num_gpus</span></code> parameters must be constant across both calls.</p>
</div>
</section>
</section>
<section id="script">
<span id="data-structures-script"></span><h2>Script<a class="headerlink" href="#script" title="Permalink to this heading">#</a></h2>
<p>Data processing is an essential step in most machine
learning workflows.  For this reason, RedisAI provides
the ability to evaluate PyTorch programs using the hardware
co-located with the backend database (either CPU or GPU).
The SmartRedis <code class="docutils literal notranslate"><span class="pre">Client</span></code> provides functions for users to
place a script in the database, retrieve a script from the
database, and run a script.</p>
<section id="id2">
<h3>Sending<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>A script is placed in the database through the <code class="docutils literal notranslate"><span class="pre">Client.set_script()</span></code>
function.  While data types may differ, the function parameters
are uniform across all SmartRedis clients, and as an example, the C++
<code class="docutils literal notranslate"><span class="pre">set_script()</span></code> function is shown below.  The function signature
is quite simple for placing a script in the database, only
a name for the script, hardware for execution, and the script text
need to be provided by the user.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="kt">void</span><span class="w"> </span><span class="nf">set_script</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">name</span><span class="p">,</span>
<span class="w">                </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&amp;</span><span class="w"> </span><span class="n">device</span><span class="p">,</span>
<span class="w">                </span><span class="k">const</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">string_view</span><span class="o">&amp;</span><span class="w"> </span><span class="n">script</span><span class="p">);</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>With a clustered Redis backend configuration, <code class="docutils literal notranslate"><span class="pre">Client.set_script()</span></code>
will distribute a copy of the script to each database node in the
cluster.  As a result, the script that has been
placed in the cluster with <code class="docutils literal notranslate"><span class="pre">Client.set_script()</span></code>
will not be addressable directly with the Redis CLI because
of key manipulation that is required to accomplish
this distribution.  Despite the internal key
manipulation, scripts in a clustered Redis backend that have been
set through the SmartRedis <code class="docutils literal notranslate"><span class="pre">Client</span></code> can be accessed
and run through the SmartRedis <code class="docutils literal notranslate"><span class="pre">Client</span></code> API
using the name provided to <code class="docutils literal notranslate"><span class="pre">set_script()</span></code>.  The user
does not need any knowledge of the cluster script distribution
to perform RedisAI script actions.  Moreover,
a script set by one SmartRedis client (e.g. Python) on a Redis
cluster is addressable with the same name through another
client (e.g. C++).</p>
</div>
<p>Finally, there is a similar function in each client,
<code class="docutils literal notranslate"><span class="pre">Client.set_script_from_file()</span></code>, that will read a
script from file and set it in the database.</p>
</section>
<section id="id3">
<h3>Retrieving<a class="headerlink" href="#id3" title="Permalink to this heading">#</a></h3>
<p>A script can be retrieved from the database using the
<code class="docutils literal notranslate"><span class="pre">Client.get_script()</span></code> function.  While the return
type varies between languages, only the script name
that was used with <code class="docutils literal notranslate"><span class="pre">Client.set_script()</span></code> is needed
to reference the script in the database.  Note that
in a clustered Redis backend configuration, only one copy of the
script is returned to the user.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">Client.get_script()</span></code> will allocate memory to retrieve
the script from the database, and this memory will not
be freed until the Client object is destroyed.</p>
</div>
</section>
<section id="id4">
<h3>Executing<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>A script can be executed using the <code class="docutils literal notranslate"><span class="pre">Client.run_script()</span></code> function.
The only required inputs to execute a script are the script name,
the name of the function in the script to execute, a list of input
tensor names, and a list of output tensor names.
If using a clustered Redis backend configuration, a copy of the script
referenced by the provided name will be chosen based on data locality.
It is worth noting that the names of input and output tensors will be
altered with ensemble member identifications if the SmartSim
ensemble compatibility features are used.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>DataSet tensors can be used as <code class="docutils literal notranslate"><span class="pre">run_script()</span></code> input tensors,
but the name provided to <code class="docutils literal notranslate"><span class="pre">run_script()</span></code> must be prefixed with
the <code class="docutils literal notranslate"><span class="pre">DataSet</span></code> name in the pattern <code class="docutils literal notranslate"><span class="pre">{dataset_name}.tensor_name</span></code>.</p>
</div>
</section>
<section id="id5">
<h3>Support on Systems with Multiple GPUs<a class="headerlink" href="#id5" title="Permalink to this heading">#</a></h3>
<p>SmartRedis has special support for scripts on systems with multiple GPUs.
On these systems, the script can be set via the <code class="docutils literal notranslate"><span class="pre">Client.set_script_multigpu()</span></code>
function, which differs from the <code class="docutils literal notranslate"><span class="pre">Client.set_script()</span></code> function only in that
(1) there is no need to specify a device (GPU is implicit) and (2) the caller
must supply the index of the first GPU to use with the script and the total
number of GPUs on the system’s nodes to use with the script. The function will
then create separate copies of the script for each GPU by appending <code class="docutils literal notranslate"><span class="pre">.GPU:n</span></code>
to the supplied name, where <code class="docutils literal notranslate"><span class="pre">n</span></code> is a number from <code class="docutils literal notranslate"><span class="pre">first_gpu</span></code> to
<code class="docutils literal notranslate"><span class="pre">first_gpu</span> <span class="pre">+</span> <span class="pre">num_gpus</span> <span class="pre">-</span> <span class="pre">1</span></code>, inclusive.</p>
<p>Executing scripts on systems with multiple GPUs may be done via the
<code class="docutils literal notranslate"><span class="pre">Client.run_script_multigpu()</span></code> function. This method parallels
<code class="docutils literal notranslate"><span class="pre">Client.run_script()</span></code> except that it requires three additional parameters:
the first GPU to use for execution, the number of GPUs to use for execution,
and an offset for the currently executing thread or image. The script execution
is then dispatched to the copy of the script on the GPU corresponding to
<code class="docutils literal notranslate"><span class="pre">first_gpu</span></code> plus the offset modulo <code class="docutils literal notranslate"><span class="pre">num_gpus</span></code>.  The image offset may
be an MPI rank, or a thread ID, or any other indexing scheme.</p>
<p>Finally, scripts stored for multiple GPUs may be deleted via the
<code class="docutils literal notranslate"><span class="pre">Client.delete_script_multigpu()</span></code> function. This method parallels
<code class="docutils literal notranslate"><span class="pre">Client.delete_script()</span></code> except that it requires two additional parameters:
the first GPU and the number of GPUs that the model was stored with. This
function will delete all the extra copies of the model that were stored
via <code class="docutils literal notranslate"><span class="pre">Client.set_script_multigpu()</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In order for a script to be executed via <code class="docutils literal notranslate"><span class="pre">Client.run_script_multigpu()</span></code>,
or deleted via <code class="docutils literal notranslate"><span class="pre">Client.delete_script_multigpu()</span></code>,
it must have been set via <code class="docutils literal notranslate"><span class="pre">Client.set_script_multigpu()</span></code>. The
<code class="docutils literal notranslate"><span class="pre">first_gpu</span></code> and <code class="docutils literal notranslate"><span class="pre">num_gpus</span></code> parameters must be constant across both calls.</p>
</div>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="sr_fortran_walkthrough.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Fortran</p>
      </div>
    </a>
    <a class="right-next"
       href="sr_dataset_conversions.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">DataSet Conversions</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tensor">Tensor</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sending">Sending</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#retrieving">Retrieving</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset">Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#build-and-send-a-dataset">Build and Send a DataSet</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#retrieving-a-dataset">Retrieving a DataSet</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#aggregating">Aggregating</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model">Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#build-and-send-a-model">Build and Send a Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Retrieving</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#executing">Executing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#support-on-systems-with-multiple-gpus">Support on Systems with Multiple GPUs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#script">Script</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Sending</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">Retrieving</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">Executing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">Support on Systems with Multiple GPUs</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Cray Labs
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2021-2024, Hewlett Packard Enterprise.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  Questions? You can contact <a href="mailto:craylabs@hpe.com">contact us</a> or <a href="https://join.slack.com/t/craylabs/shared_invite/zt-nw3ag5z5-5PS4tIXBfufu1bIvvr71UA">join us on Slack!</a>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>