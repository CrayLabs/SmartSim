

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Machine Learning &mdash; SmartSim 0.3.2 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Experiments" href="../experiment.html" />
    <link rel="prev" title="Online Analysis" href="lattice_boltz_analysis.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> SmartSim
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Overview of SmartSim</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community.html">Community</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="01_getting_started/01_getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="using_clients.html">Using SmartRedis Clients</a></li>
<li class="toctree-l1"><a class="reference internal" href="lattice_boltz_analysis.html">Online Analysis</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Machine Learning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#your-first-inference-session">4.1 Your First Inference Session</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pytorch">4.2 PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensorflow-and-keras">4.2 TensorFlow and Keras</a></li>
<li class="toctree-l2"><a class="reference internal" href="#onnx">4.3 ONNX</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#kmeans">KMeans</a></li>
<li class="toctree-l3"><a class="reference internal" href="#random-forest">Random Forest</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">SmartSim</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../experiment.html">Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../orchestrator.html">Orchestrator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../launchers.html">Launchers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/smartsim_api.html">SmartSim API</a></li>
</ul>
<p class="caption"><span class="caption-text">SmartRedis</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../smartredis.html">SmartRedis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sr_data_structures.html">Data Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sr_runtime.html">Runtime Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/smartredis_api.html">SmartRedis API</a></li>
</ul>
<p class="caption"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../code_of_conduct.html">Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer.html">Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SmartSim</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Machine Learning</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/tutorials/inference.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="machine-learning">
<h1>Machine Learning<a class="headerlink" href="#machine-learning" title="Permalink to this headline">¶</a></h1>
<p>Compiling TensorFlow or PyTorch runtimes into each existing simulation is
difficult. Maintaining that type of integration with the rapidly growing and changing
APIs of libraries like TensorFlow and PyTorch is even more difficult.</p>
<p>Instead of forcing dependencies on the simulation code, SmartSim itself maintains those dependencies
and provides simulations runtime access to them through the <code class="docutils literal notranslate"><span class="pre">Orchestrator</span></code> database.</p>
<p>Simulations in Fortran, C, C++ and Python can call into PyTorch, TensorFlow,
and any library that supports the ONNX format without compiling in ML libraries into the
simulation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>While the SmartRedis examples below are written in Python, SmartRedis is implemented
in C, C++ and Fortran as well. Fortran, C, and C++ applications can all call the
same Machine Learning libraries/models as the examples below.</p>
</div>
<div class="section" id="your-first-inference-session">
<h2>4.1 Your First Inference Session<a class="headerlink" href="#your-first-inference-session" title="Permalink to this headline">¶</a></h2>
<p id="infrastructure-code">SmartSim performs online inference by using the SmartRedis clients to call into the
Machine Learning runtimes linked into the Orchestrator database.</p>
<p>Therefore, to perform inference, you must first create an Orchestrator database and
launch it. The code below can be used to launch a database with SmartSim and Python
script that uses the SmartRedis Python client to perform innovations of the ML runtimes.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">smartsim</span> <span class="kn">import</span> <span class="n">Experiment</span>
<span class="kn">from</span> <span class="nn">smartsim.database</span> <span class="kn">import</span> <span class="n">Orchestrator</span>
<span class="kn">from</span> <span class="nn">smartsim.settings</span> <span class="kn">import</span> <span class="n">RunSettings</span>

<span class="n">exp</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span><span class="s2">&quot;inference-session&quot;</span><span class="p">,</span> <span class="n">launcher</span><span class="o">=</span><span class="s2">&quot;local&quot;</span><span class="p">)</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">Orchestrator</span><span class="p">(</span><span class="n">port</span><span class="o">=</span><span class="mi">6780</span><span class="p">)</span>

<span class="n">script</span> <span class="o">=</span> <span class="s2">&quot;inference.py&quot;</span>
<span class="n">settings</span> <span class="o">=</span> <span class="n">RunSettings</span><span class="p">(</span><span class="s2">&quot;python&quot;</span><span class="p">,</span> <span class="n">exe_args</span><span class="o">=</span><span class="n">script</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s2">&quot;model_using_ml&quot;</span><span class="p">,</span> <span class="n">settings</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">attach_generator_files</span><span class="p">(</span><span class="n">to_copy</span><span class="o">=</span><span class="n">script</span><span class="p">)</span>

<span class="n">exp</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">db</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">block</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">summary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">exp</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="n">db</span><span class="p">)</span>
</pre></div>
</div>
<p>The above script will first launch the database, and then the script
containing the SmartRedis client code Python script. The code here could
easily be adapted to launch a C, C++, or Fortran application containing
the SmartRedis clients in those languages as well.</p>
<p>Below are a few examples of scripts that could be used with the above
code to perform online inference with various ML backends supported
by SmartSim.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Online inference is not online training.
The following code examples do not include code to train the models shown.</p>
</div>
</div>
<div class="section" id="pytorch">
<h2>4.2 PyTorch<a class="headerlink" href="#pytorch" title="Permalink to this headline">¶</a></h2>
<p>The Orchestrator supports both <a class="reference external" href="https://pytorch.org/">PyTorch</a> models and <a class="reference external" href="https://pytorch.org/docs/stable/jit.html">TorchScript</a> functions and scripts
in <a class="reference external" href="https://pytorch.org/">PyTorch</a> 1.7.1. To use ONNX in SmartSim, specify
<code class="docutils literal notranslate"><span class="pre">TORCH</span></code> as the argument for <em>backend</em> in the call to <code class="docutils literal notranslate"><span class="pre">client.set_model</span></code> or
<code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code>.</p>
<p>The below script can be used with the <a class="reference internal" href="#infrastructure-code"><span class="std std-ref">SmartSim code</span></a>
above to launch an inference session with a PyTorch model.</p>
<p>First, a PyTorch model is defined.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">smartredis</span> <span class="kn">import</span> <span class="n">Client</span>

<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9216</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
<p>Next we create a function to “jit-trace” the model and save it to a buffer.
If you aren’t familier with the concept of tracing, take a look at the
Torch documentation for <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html#torch.jit.trace">trace</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">example_forward_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_torch_model</span><span class="p">(</span><span class="n">torch_module</span><span class="p">,</span> <span class="n">example_forward_input</span><span class="p">):</span>

    <span class="c1"># perform the trace of the nn.Module.forward() method</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">torch_module</span><span class="p">,</span> <span class="n">example_forward_input</span><span class="p">)</span>

    <span class="c1"># save the traced module to a buffer</span>
    <span class="n">model_buffer</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">model_buffer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model_buffer</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>
</pre></div>
</div>
<dl class="simple">
<dt>Lastly, we use the SmartRedis Python client to</dt><dd><ol class="arabic simple">
<li><p>Connect to the database</p></li>
<li><p>Put a batch of 20 tensors into the database  (<code class="docutils literal notranslate"><span class="pre">put_tensor</span></code>)</p></li>
<li><p>Set the Torch model in the database (<code class="docutils literal notranslate"><span class="pre">set_model</span></code>)</p></li>
<li><p>Run the model on the batch of tensors (<code class="docutils literal notranslate"><span class="pre">run_model</span></code>)</p></li>
<li><p>Retrieve the result (<code class="docutils literal notranslate"><span class="pre">get_tensor</span></code>)</p></li>
</ol>
</dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">cluster</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="c1"># put the PyTorch CNN in the database in GPU memory</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="s2">&quot;cnn&quot;</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="s2">&quot;TORCH&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;GPU&quot;</span><span class="p">)</span>

<span class="c1"># execute the model, supports a variable number of inputs and outputs</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;cnn&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">])</span>

<span class="c1"># get the output</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction: </span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Since we are launching the inference
script through SmartSim, we do not need to specify the address of the
database as SmartSim will connect the Client for us. Additionally,
<code class="docutils literal notranslate"><span class="pre">cluster=False</span></code> is specified so the client will not attempt to find
other cluster shards on the network.</p>
<p>If running on CPU, be sure to change the argument in the <code class="docutils literal notranslate"><span class="pre">set_model</span></code> call
above to <code class="docutils literal notranslate"><span class="pre">CPU</span></code>.</p>
</div>
<div class="section" id="tensorflow-and-keras">
<h2>4.2 TensorFlow and Keras<a class="headerlink" href="#tensorflow-and-keras" title="Permalink to this headline">¶</a></h2>
<p>The Orchestrator, in addition to PyTorch, is built with <a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a> and <a class="reference external" href="https://keras.io/">Keras</a> support by default.
Currently TensorFlow 2.4.2 is supported, but the graph of the model must be frozen
before it is placed in the database. This is the same process for both Keras and
TensorFlow.</p>
<p>The example below shows how to prepare a simple Keras model for use with SmartSim.
This script can be used with the <a class="reference internal" href="#infrastructure-code"><span class="std std-ref">SmartSim code</span></a>
above to launch an inference session with a TensorFlow or Keras model.</p>
<p>First, a simple Keras Convolutional Neural Network is defined.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>


<span class="c1"># create a simple Fully connected network in Keras</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">=</span><span class="p">[</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;flatten&quot;</span><span class="p">),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;dense&quot;</span><span class="p">),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;FCN&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Compile model with optimizer</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
            <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
            <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>After a model is created (trained or not), the graph of the model is
frozen saved to file so the client method <code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code>
can load it into the database.</p>
<p>SmartSim includes a utility to freeze the graph of a TensorFlow or Keras model in
<a class="reference internal" href="../api/smartsim_api.html#smartsim-tf-api"><span class="std std-ref">smartsim.tf</span></a>. To use TensorFlow or Keras in SmartSim, specify
<code class="docutils literal notranslate"><span class="pre">TF</span></code> as the argument for <em>backend</em> in the call to <code class="docutils literal notranslate"><span class="pre">client.set_model</span></code> or
<code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code>.</p>
<p>Note that TensorFlow and Keras, unlike the other ML libraries supported by
SmartSim, requires an <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">output</span></code> argument in the call to
<code class="docutils literal notranslate"><span class="pre">set_model</span></code>. These arguments correspond to the layer names of the
created model. The <a class="reference internal" href="../api/smartsim_api.html#smartsim-tf-api"><span class="std std-ref">smartsim.tf.freeze_model</span></a> utility
returns these values for convenience as shown below.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">smartredis</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="kn">from</span> <span class="nn">smartsim.tf</span> <span class="kn">import</span> <span class="n">freeze_model</span>


<span class="c1"># SmartSim utility for Freezing the model</span>
<span class="n">model_path</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">freeze_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;fcn.pb&quot;</span><span class="p">)</span>

<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">cluster</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># TensorFlow backed requires named inputs and outputs on graph</span>
<span class="c1"># this differs from PyTorch and ONNX.</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_model_from_file</span><span class="p">(</span>
    <span class="s2">&quot;keras_fcn&quot;</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="s2">&quot;TF&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span>
<span class="p">)</span>

<span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;keras_fcn&quot;</span><span class="p">,</span> <span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;output&quot;</span><span class="p">)</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="onnx">
<h2>4.3 ONNX<a class="headerlink" href="#onnx" title="Permalink to this headline">¶</a></h2>
<p>ONNX is a standard format for representing models. A number of different Machine Learning
Libraries are supported by ONNX and can be readily used with SmartSim.</p>
<p>Some popular ones are:</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org">Scikit-learn</a></p></li>
<li><p><a class="reference external" href="https://xgboost.readthedocs.io">XGBoost</a></p></li>
<li><p><a class="reference external" href="https://catboost.ai">CatBoost</a></p></li>
<li><p><a class="reference external" href="https://www.tensorflow.org/">TensorFlow</a></p></li>
<li><p><a class="reference external" href="https://keras.io/">Keras</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/">PyTorch</a></p></li>
<li><p><a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/">LightGBM</a></p></li>
<li><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a></p></li>
</ul>
</div></blockquote>
<p>As well as some that are not listed. There are also many tools to help convert
models to ONNX.</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://github.com/onnx/onnxmltools">onnxmltools</a></p></li>
<li><p><a class="reference external" href="https://github.com/onnx/sklearn-onnx/">skl2onnx</a></p></li>
<li><p><a class="reference external" href="https://github.com/onnx/tensorflow-onnx/">tensorflow-onnx</a></p></li>
</ul>
</div></blockquote>
<p>And PyTorch has it’s own converter.</p>
<p>Below are some examples of a few models in <a class="reference external" href="https://scikit-learn.org">Scikit-learn</a> that are converted
into ONNX format for use with SmartSim. To use ONNX in SmartSim, specify
<code class="docutils literal notranslate"><span class="pre">ONNX</span></code> as the argument for <em>backend</em> in the call to <code class="docutils literal notranslate"><span class="pre">client.set_model</span></code> or
<code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code>.</p>
<p>These scripts can be used with the <a class="reference internal" href="#infrastructure-code"><span class="std std-ref">SmartSim code</span></a>
above to launch an inference session with any of the supported ONNX libraries.</p>
<div class="section" id="kmeans">
<h3>KMeans<a class="headerlink" href="#kmeans" title="Permalink to this headline">¶</a></h3>
<p>K-means clustering is an unsupervised ML algorithm. It is used to categorize data points
into f groups (“clusters”). Scikit Learn has a built in implementation of K-means clustering
and it is easily converted to ONNX for use with SmartSim through <a class="reference external" href="http://onnx.ai/sklearn-onnx/auto_examples/plot_convert_syntax.html">skl2onnx.to_onnx</a>.</p>
<p>Since the KMeans model returns two outputs, we provide the <code class="docutils literal notranslate"><span class="pre">client.run_model</span></code> call
with two <code class="docutils literal notranslate"><span class="pre">outputs</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tr</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">tr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">tr</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">target_opset</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># dummy data</span>
<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>

<span class="n">client</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="s2">&quot;kmeans&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;ONNX&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;kmeans&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="s2">&quot;transform&quot;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="random-forest">
<h3>Random Forest<a class="headerlink" href="#random-forest" title="Permalink to this headline">¶</a></h3>
<p>The Random Forest example uses the Iris dataset from Scikit Learn to train a
RandomForestRegressor. As with the other examples, the skl2onnx function
<a class="reference external" href="http://onnx.ai/sklearn-onnx/auto_examples/plot_convert_syntax.html">skl2onnx.to_onnx</a> is used to convert the model to ONNX format.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">clr</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">clr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">rf_model</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">clr</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">6.4</span><span class="p">,</span> <span class="mf">2.8</span><span class="p">,</span> <span class="mf">5.6</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>

<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="s2">&quot;rf_regressor&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;ONNX&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;rf_regressor&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../experiment.html" class="btn btn-neutral float-right" title="Experiments" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="lattice_boltz_analysis.html" class="btn btn-neutral float-left" title="Online Analysis" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Hewlett Packard Enterprise.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>