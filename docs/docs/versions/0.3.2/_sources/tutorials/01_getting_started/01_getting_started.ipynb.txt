{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this notebook, we will walk through the most basic functionalities of SmartSim.\n",
    "\n",
    " - Creating and Running Models\n",
    " - Creating and Running Ensembles\n",
    " - Running and Communicating with the Orchestrator\n",
    " - Ensembles using SmartRedis\n",
    "\n",
    "## 1.1 Running Models \n",
    "\n",
    "`Experiment`s are how users define workflows in SmartSim. The `Experiment` is used to create `Model` instances which represent applications, scripts, or largely any program. An experiment can start and stop a `Model` and monitor execution.\n",
    "\n",
    "We begin by importing the modules we need: `Experiment` and `RunSettings`.\n",
    "\n",
    "`RunSettings` help parameterize *how* a `Model` should be executed provided the system and available computational resources. There are many types of `RunSettings` in SmartSim. The base `RunSettings` class defines parameters for running *locally*, meaning on a laptop, workstation or single compute node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from smartsim import Experiment\n",
    "from smartsim.settings import RunSettings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this notebook, we will incrementally build an `Experiment`. We start from the simplest case: A single `Model` instance\n",
    "\n",
    "Our first `Model` will simply print `hello`, using the shell command `echo`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Experiment and specify to launch locally\n",
    "exp = Experiment(name=\"getting-started\", launcher=\"local\")\n",
    "\n",
    "# create our simple model\n",
    "settings = RunSettings(exe=\"echo\", exe_args=\"hello\")\n",
    "M1 = exp.create_model(name=\"tutorial-model\", run_settings=settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `Model` has been created by the `Experiment`, it can be started.\n",
    "\n",
    "By setting `summary=True`, we can see a summary of the experiment printed before it is launched. The summary will stay for 10 seconds, and it is useful as a last check. If we set `summary=False`, then the experiment would be launched immediately.\n",
    "\n",
    "We also explicitly set `block=True` (even though it is the default), so that  `Experiment.start` waits until the last `Model` has finished before returning: it will act like a job monitor, letting us know if processes run, complete, or fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[36;1m=== LAUNCH SUMMARY ===\u001b[0m\n",
      "\u001b[32;1mExperiment: getting-started\u001b[0m\n",
      "\u001b[32mExperiment Path: /Users/spartee/Dropbox/Cray/smartsim/tutorials/01_getting_started/getting-started\u001b[0m\n",
      "\u001b[32mLaunching with: local\u001b[0m\n",
      "\u001b[32m# of Ensembles: 0\u001b[0m\n",
      "\u001b[32m# of Models: 1\u001b[0m\n",
      "\u001b[32mDatabase: no\u001b[0m\n",
      "\n",
      "\u001b[36;1m=== MODELS ===\u001b[0m\n",
      "\u001b[32;1mtutorial-model\u001b[0m\n",
      "\u001b[32mModel Parameters: \n",
      "{}\u001b[0m\n",
      "\u001b[32mModel Run Settings: \n",
      "Executable: /bin/echo\n",
      "Executable arguments: ['hello']\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:30:47 C02YN0J3JG5M SmartSim[49287] INFO tutorial-model(49432): Completed\n"
     ]
    }
   ],
   "source": [
    "exp.start(M1, block=True, summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has completed. Let's look at the content of the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of tutorial-model.out:\n",
      "hello\n",
      "\n",
      "Content of tutorial-model.err:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.listdir('.')\n",
    "\n",
    "outputfile = './tutorial-model.out'\n",
    "errorfile = './tutorial-model.err'\n",
    "\n",
    "print(\"Content of tutorial-model.out:\")\n",
    "with open(outputfile, 'r') as fin:\n",
    "    print(fin.read())\n",
    "print(\"Content of tutorial-model.err:\")\n",
    "with open(errorfile, 'r') as fin:\n",
    "    print(fin.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that two files, `tutorial-model-1.out` and `tutorial-model-1.err` have been created. The `.out` file contains the output generated by `model-1`, and the `.err` file would contain the error messages generated by it. Since there were no errors, the `.err` file is empty.\n",
    "\n",
    "Now let's run two different `Model` instances at the same time. This is just as easy as running one `Model`, and takes the same steps. This time, we will skip the summary. For each `Model`, we create a `RunSettings` object: it is recommended to always create separate `RunSettings` objects for each `Model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:32:18 C02YN0J3JG5M SmartSim[49287] INFO tutorial-model-1(50330): Completed\n",
      "19:32:19 C02YN0J3JG5M SmartSim[49287] INFO tutorial-model-2(50337): Running\n",
      "19:32:20 C02YN0J3JG5M SmartSim[49287] INFO tutorial-model-2(50337): Completed\n"
     ]
    }
   ],
   "source": [
    "run_settings_1 = RunSettings(\"sleep\", \"3\")\n",
    "run_settings_2 = RunSettings(\"sleep\", \"5\")\n",
    "\n",
    "model_1 = exp.create_model(\"tutorial-model-1\", run_settings_1)\n",
    "model_2 = exp.create_model(\"tutorial-model-2\", run_settings_2)\n",
    "exp.start(model_1, model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For users of parallel applications, launch binaries can also be specified in `RunSettings`. For example, if `mpirun` is installed on the system, we can run a model through it, by specifying it as `run_command` in `RunSettings`. Since `mpirun` takes arguments (e.g. to define how many processes will be run), we pass them by defining `run_args` in `RunSettings`.\n",
    "\n",
    "Please note that to run this you need to have OpenMPI installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[36;1m=== LAUNCH SUMMARY ===\u001b[0m\n",
      "\u001b[32;1mExperiment: getting-started\u001b[0m\n",
      "\u001b[32mExperiment Path: /Users/spartee/Dropbox/Cray/smartsim/tutorials/01_getting_started/getting-started\u001b[0m\n",
      "\u001b[32mLaunching with: local\u001b[0m\n",
      "\u001b[32m# of Ensembles: 0\u001b[0m\n",
      "\u001b[32m# of Models: 1\u001b[0m\n",
      "\u001b[32mDatabase: no\u001b[0m\n",
      "\n",
      "\u001b[36;1m=== MODELS ===\u001b[0m\n",
      "\u001b[32;1mtutorial-model-mpirun\u001b[0m\n",
      "\u001b[32mModel Parameters: \n",
      "{}\u001b[0m\n",
      "\u001b[32mModel Run Settings: \n",
      "Executable: /bin/echo\n",
      "Executable arguments: ['hello', 'world!']\n",
      "Run Command: mpirun\n",
      "Run arguments: {'-np': 2}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:35:47 C02YN0J3JG5M SmartSim[49287] INFO tutorial-model-mpirun(52447): Completed\n"
     ]
    }
   ],
   "source": [
    "openmpi_settings = RunSettings(\"echo\",\n",
    "                           \"hello world!\",\n",
    "                           run_command=\"mpirun\",\n",
    "                           run_args={\"-np\": 2}) # note that for base ``RunSettings`` run_args passed literally\n",
    "                      \n",
    "ompi_model = exp.create_model(\"tutorial-model-mpirun\", openmpi_settings)\n",
    "exp.start(ompi_model, summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, since we passed `-np 2` to `mpirun`, in the output file we should find the line `hello world!` twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of tutorial-model-mpirun.out:\n",
      "hello world!\n",
      "hello world!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputfile = './tutorial-model-mpirun.out'\n",
    "errorfile = './tutorial-model-mpirun.err'\n",
    "\n",
    "print(\"Content of tutorial-model-mpirun.out:\")\n",
    "with open(outputfile, 'r') as fin:\n",
    "    print(fin.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Running Ensembles\n",
    "\n",
    "In the previous example, the two `Model` instances were created separately. There are more convenient ways of doing this, through `Ensemble`s. `Ensemble`s are groups of `Model` instances that can be treated as a single reference. We start by specifying `RunSettings` similar to how we did with our `Model`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_settings = RunSettings(exe=\"sleep\", exe_args=\"3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, instead of creating it as we did before, we use `create_ensemble`. Let's assume we want to run the same experiment four times in parallel, then we will pass the `replicas=4` argument and simply start the `Ensemble`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[36;1m=== LAUNCH SUMMARY ===\u001b[0m\n",
      "\u001b[32;1mExperiment: getting-started\u001b[0m\n",
      "\u001b[32mExperiment Path: /Users/spartee/Dropbox/Cray/smartsim/tutorials/01_getting_started/getting-started\u001b[0m\n",
      "\u001b[32mLaunching with: local\u001b[0m\n",
      "\u001b[32m# of Ensembles: 1\u001b[0m\n",
      "\u001b[32m# of Models: 0\u001b[0m\n",
      "\u001b[32mDatabase: no\u001b[0m\n",
      "\n",
      "\u001b[36;1m=== ENSEMBLES ===\u001b[0m\n",
      "\u001b[32;1mensemble-replica\u001b[0m\n",
      "\u001b[32m# of models in ensemble: 4\u001b[0m\n",
      "\u001b[32mLaunching as batch: False\u001b[0m\n",
      "\u001b[32mRun Settings: \n",
      "Executable: /bin/sleep\n",
      "Executable arguments: ['3']\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:39:43 C02YN0J3JG5M SmartSim[49287] INFO ensemble-replica_0(54811): Completed\n",
      "19:39:43 C02YN0J3JG5M SmartSim[49287] INFO ensemble-replica_2(54813): Completed\n",
      "19:39:44 C02YN0J3JG5M SmartSim[49287] INFO ensemble-replica_1(54812): Completed\n",
      "19:39:44 C02YN0J3JG5M SmartSim[49287] INFO ensemble-replica_3(54814): Completed\n",
      "19:39:45 C02YN0J3JG5M SmartSim[49287] INFO ensemble-replica_1(54812): Completed\n",
      "19:39:45 C02YN0J3JG5M SmartSim[49287] INFO ensemble-replica_3(54814): Completed\n"
     ]
    }
   ],
   "source": [
    "ensemble = exp.create_ensemble(\"ensemble-replica\", replicas=4, run_settings=ens_settings)\n",
    "exp.start(ensemble, summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, we see that four copies of our `Model`, named *ensemble-replica_0*, *ensemble-replica_1*, ... were run. In each output file, we will see that the same output was generated.\n",
    "\n",
    "Now let's imagine that we don't want to run the *same* model four times, but we want to run variations of it. One way of doing this would be to define four models, and starting them through the `Experiment`.\n",
    "\n",
    "For few, simple `Model`s, this would be OK, but what if we needed to run a large number of models, which only differ for some parameter? Defining and adding each one separately would be tedious. For such cases, we will rely on a parameterized `Ensemble` of models.\n",
    "\n",
    "Our goal is to run \n",
    "\n",
    "```python output_my_parameter.py```\n",
    "\n",
    "with multiple parameter values. Clearly, we could pass the parameters as arguments, but in some cases, this could not be possible (e.g. if the parameters were stored in a file or the executable would not accept them from the command line). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = RunSettings(exe=\"python\", exe_args=\"output_my_parameter.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define the parameters we are going to set:\n",
    "\n",
    " 1. `tutorial_name`\n",
    " 2. `tutorial_parameter`\n",
    " \n",
    "In the original file `output_my_parameter.py`, which acts as a template, they occur as `;tutorial_name;` and `;tutorial_parameter;`. The semi-colons are used to perform a regexp substitution with the desired values. The semi-colon in this case, is called a *tag* and can be changed.\n",
    "\n",
    "We pass them to `Experiment.create_ensemble`, along with the argument `perm_strategy=\"all_perm\"`. This argument means that we want all possible permutations of the given parameters, which are stored in the argument `params`. We have two options for both parameters, thus our ensemble will run 4 instances of the same `Experiment`, just using a different copy of `output_my_parameter.py` created by calling `Experiment.generate()`. We attach the template file to the `Ensemble` instance, generate the augmented python files, and run the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:48:20 C02YN0J3JG5M SmartSim[49287] INFO ensemble_0(60008): Completed\n",
      "19:48:20 C02YN0J3JG5M SmartSim[49287] INFO ensemble_1(60009): Completed\n",
      "19:48:20 C02YN0J3JG5M SmartSim[49287] INFO ensemble_2(60010): Completed\n",
      "19:48:21 C02YN0J3JG5M SmartSim[49287] INFO ensemble_3(60012): Completed\n",
      "19:48:22 C02YN0J3JG5M SmartSim[49287] INFO ensemble_3(60012): Completed\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"tutorial_name\": [\"Ellie\", \"John\"],\n",
    "    \"tutorial_parameter\": [2, 11]\n",
    "}\n",
    "ensemble = exp.create_ensemble(\"ensemble\", params=params, run_settings=rs, perm_strategy=\"all_perm\")\n",
    "\n",
    "# to_configure specifies that the files attached should be read and tags should be looked for\n",
    "config_file = \"./output_my_parameter.py\"\n",
    "ensemble.attach_generator_files(to_configure=config_file)\n",
    "\n",
    "exp.generate(ensemble, overwrite=True)\n",
    "exp.start(ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the output that four instances of our experiment were run, each one named like the `Experiment`, with a numeric suffix at the end: `ensemble_0`, `ensemble_1`, ... each ensemble member generated its own output files, which will be stored in `getting-started/ensemble/ensemble_0`, `getting-started/ensemble/ensemble_1`, and so on as the call to ``Experiment.generate()`` will created isolated output directories for each created `Model` in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content of getting-started/ensemble/ensemble_0/ensemble_0.out:\n",
      "Hello, my name is Ellie and my parameter is 2\n",
      "\n",
      "Content of getting-started/ensemble/ensemble_1/ensemble_1.out:\n",
      "Hello, my name is Ellie and my parameter is 11\n",
      "\n",
      "Content of getting-started/ensemble/ensemble_2/ensemble_2.out:\n",
      "Hello, my name is John and my parameter is 2\n",
      "\n",
      "Content of getting-started/ensemble/ensemble_3/ensemble_3.out:\n",
      "Hello, my name is John and my parameter is 11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ensemble_id in range(4):\n",
    "    outputfile = 'getting-started/ensemble/ensemble_' + str(ensemble_id)+\"/ensemble_\"+ str(ensemble_id)+\".out\"\n",
    "\n",
    "    print(f\"Content of {outputfile}:\")\n",
    "    with open(outputfile, 'r') as fin:\n",
    "        print(fin.read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! All possible permutations of the input parameters were used to execute the experiment! Sometimes, the parameter space can be too large to be explored exhaustively. In that case, we can use a different permutation strategy, i.e. `random`. For example, if we want to only use two possible random combinations of our parameter space, we can run the following code, where we specify `n_models=2` and `perm_strategy=\"random\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:51:29 C02YN0J3JG5M SmartSim[49287] INFO Working in previously created experiment\n",
      "19:51:34 C02YN0J3JG5M SmartSim[49287] INFO ensemble_0(62039): Completed\n",
      "19:51:34 C02YN0J3JG5M SmartSim[49287] INFO ensemble_1(62040): Completed\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"tutorial_name\": [\"Ellie\", \"John\"],\n",
    "    \"tutorial_parameter\": [2, 11]\n",
    "}\n",
    "ensemble = exp.create_ensemble(\"ensemble\", params=params, run_settings=rs, perm_strategy=\"random\", n_models=2)\n",
    "config_file = \"./output_my_parameter.py\"\n",
    "ensemble.attach_generator_files(to_configure=config_file)\n",
    "\n",
    "exp.generate(ensemble, overwrite=True)\n",
    "exp.start(ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possible permutation strategy is `stepped`, but it is also possible to pass a function, which will need to generate combinations of parameters starting from the dictionary. Please refer to the documentation to learn more about this.\n",
    "\n",
    "\n",
    "It is also possible to use different delimiters for the parameter regexp. For example, if instead of `;`, we want to use `@`, we can set it as `tag` in `generate`. We have to use a different version of the parameterized file, one named `output_my_parameter_new_tag.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:52:39 C02YN0J3JG5M SmartSim[49287] INFO Working in previously created experiment\n",
      "19:52:44 C02YN0J3JG5M SmartSim[49287] INFO ensemble_new_tag_0(62747): Completed\n",
      "19:52:44 C02YN0J3JG5M SmartSim[49287] INFO ensemble_new_tag_1(62748): Completed\n",
      "19:52:44 C02YN0J3JG5M SmartSim[49287] INFO ensemble_new_tag_2(62749): Completed\n",
      "19:52:45 C02YN0J3JG5M SmartSim[49287] INFO ensemble_new_tag_3(62750): Completed\n",
      "19:52:46 C02YN0J3JG5M SmartSim[49287] INFO ensemble_new_tag_3(62750): Completed\n"
     ]
    }
   ],
   "source": [
    "rs = RunSettings(exe=\"python\", exe_args=\"output_my_parameter_new_tag.py\")\n",
    "params = {\n",
    "    \"tutorial_name\": [\"Ellie\", \"John\"],\n",
    "    \"tutorial_parameter\": [2, 11]\n",
    "}\n",
    "ensemble = exp.create_ensemble(\"ensemble_new_tag\", params=params, run_settings=rs, perm_strategy=\"all_perm\")\n",
    "config_file = \"./output_my_parameter_new_tag.py\"\n",
    "ensemble.attach_generator_files(to_configure=config_file)\n",
    "\n",
    "exp.generate(ensemble, overwrite=True, tag='@')\n",
    "exp.start(ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we can see all the kernels we have executed by calling `Experiment.summary()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Entity-Type</th>\n",
       "      <th>JobID</th>\n",
       "      <th>RunID</th>\n",
       "      <th>Time</th>\n",
       "      <th>Status</th>\n",
       "      <th>Returncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tutorial-model</td>\n",
       "      <td>Model</td>\n",
       "      <td>49432</td>\n",
       "      <td>0</td>\n",
       "      <td>2.001588</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tutorial-model-1</td>\n",
       "      <td>Model</td>\n",
       "      <td>50330</td>\n",
       "      <td>0</td>\n",
       "      <td>4.217252</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tutorial-model-2</td>\n",
       "      <td>Model</td>\n",
       "      <td>50337</td>\n",
       "      <td>0</td>\n",
       "      <td>6.010539</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tutorial-model-mpirun</td>\n",
       "      <td>Model</td>\n",
       "      <td>52447</td>\n",
       "      <td>0</td>\n",
       "      <td>2.004867</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ensemble-replica_0</td>\n",
       "      <td>Model</td>\n",
       "      <td>54811</td>\n",
       "      <td>0</td>\n",
       "      <td>4.628920</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ensemble-replica_2</td>\n",
       "      <td>Model</td>\n",
       "      <td>54813</td>\n",
       "      <td>0</td>\n",
       "      <td>4.216618</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ensemble-replica_1</td>\n",
       "      <td>Model</td>\n",
       "      <td>54812</td>\n",
       "      <td>0</td>\n",
       "      <td>6.428902</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ensemble-replica_3</td>\n",
       "      <td>Model</td>\n",
       "      <td>54814</td>\n",
       "      <td>0</td>\n",
       "      <td>6.017785</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ensemble_2</td>\n",
       "      <td>Model</td>\n",
       "      <td>60010</td>\n",
       "      <td>0</td>\n",
       "      <td>4.218734</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ensemble_3</td>\n",
       "      <td>Model</td>\n",
       "      <td>60012</td>\n",
       "      <td>0</td>\n",
       "      <td>6.013866</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ensemble_0</td>\n",
       "      <td>Model</td>\n",
       "      <td>60008</td>\n",
       "      <td>0</td>\n",
       "      <td>4.631225</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ensemble_0</td>\n",
       "      <td>Model</td>\n",
       "      <td>62039</td>\n",
       "      <td>1</td>\n",
       "      <td>4.216191</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ensemble_1</td>\n",
       "      <td>Model</td>\n",
       "      <td>60009</td>\n",
       "      <td>0</td>\n",
       "      <td>4.426308</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ensemble_1</td>\n",
       "      <td>Model</td>\n",
       "      <td>62040</td>\n",
       "      <td>1</td>\n",
       "      <td>4.011659</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ensemble_new_tag_0</td>\n",
       "      <td>Model</td>\n",
       "      <td>62747</td>\n",
       "      <td>0</td>\n",
       "      <td>4.634087</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ensemble_new_tag_1</td>\n",
       "      <td>Model</td>\n",
       "      <td>62748</td>\n",
       "      <td>0</td>\n",
       "      <td>4.428509</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ensemble_new_tag_2</td>\n",
       "      <td>Model</td>\n",
       "      <td>62749</td>\n",
       "      <td>0</td>\n",
       "      <td>4.219598</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ensemble_new_tag_3</td>\n",
       "      <td>Model</td>\n",
       "      <td>62750</td>\n",
       "      <td>0</td>\n",
       "      <td>6.015937</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name Entity-Type  JobID RunID      Time     Status  \\\n",
       "0          tutorial-model       Model  49432     0  2.001588  Completed   \n",
       "1        tutorial-model-1       Model  50330     0  4.217252  Completed   \n",
       "2        tutorial-model-2       Model  50337     0  6.010539  Completed   \n",
       "3   tutorial-model-mpirun       Model  52447     0  2.004867  Completed   \n",
       "4      ensemble-replica_0       Model  54811     0  4.628920  Completed   \n",
       "5      ensemble-replica_2       Model  54813     0  4.216618  Completed   \n",
       "6      ensemble-replica_1       Model  54812     0  6.428902  Completed   \n",
       "7      ensemble-replica_3       Model  54814     0  6.017785  Completed   \n",
       "8              ensemble_2       Model  60010     0  4.218734  Completed   \n",
       "9              ensemble_3       Model  60012     0  6.013866  Completed   \n",
       "10             ensemble_0       Model  60008     0  4.631225  Completed   \n",
       "11             ensemble_0       Model  62039     1  4.216191  Completed   \n",
       "12             ensemble_1       Model  60009     0  4.426308  Completed   \n",
       "13             ensemble_1       Model  62040     1  4.011659  Completed   \n",
       "14     ensemble_new_tag_0       Model  62747     0  4.634087  Completed   \n",
       "15     ensemble_new_tag_1       Model  62748     0  4.428509  Completed   \n",
       "16     ensemble_new_tag_2       Model  62749     0  4.219598  Completed   \n",
       "17     ensemble_new_tag_3       Model  62750     0  6.015937  Completed   \n",
       "\n",
       "   Returncode  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "6           0  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  \n",
       "10          0  \n",
       "11          0  \n",
       "12          0  \n",
       "13          0  \n",
       "14          0  \n",
       "15          0  \n",
       "16          0  \n",
       "17          0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Running and Communicating with the Orchestrator\n",
    "\n",
    "In this section we will see how to use `SmartRedis` clients to interact with an in-memory database launched by SmartSim called the `Orchestrator`. We start by importing the SmartRedis `Client` and the `Orchestrator` from SmartSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smartredis import Client\n",
    "from smartsim.database import Orchestrator\n",
    "import numpy as np\n",
    "\n",
    "REDIS_PORT=6899"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the `Orchestrator`. Since we are setting `launcher=\"local\"` in `Experiment`, the `Orchestrator` will run a single DB instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(\"tutorial-smartredis\", launcher=\"local\")\n",
    "\n",
    "# create and start a database\n",
    "orc = Orchestrator(port=REDIS_PORT)\n",
    "exp.generate(orc)\n",
    "exp.start(orc, block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `Orchestrator` is running, we can use SmartRedis to store NumPy tensors on the Redis DB, and get them back. This is done using the SmartSim `Client`. First, we setup a connection to the DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(address='127.0.0.1:'+str(REDIS_PORT), cluster=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use the DB to put and retrieve tensors. We need to assign a unique key to each tensor (or object) we store on the DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receive tensor:\n",
      "\n",
      " [[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "send_tensor = np.ones((4,3,3))\n",
    "\n",
    "client.put_tensor(\"tutorial_tensor_1\", send_tensor)\n",
    "\n",
    "receive_tensor = client.get_tensor(\"tutorial_tensor_1\")\n",
    "\n",
    "print('Receive tensor:\\n\\n', receive_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the SmartRedis `Client` and its possible to store and run a Pytorch neural network directly on the DB node. We first create a one-layer PyTorch Convolutional Neural Network, and save it as a jit-traced, serialized, object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# taken from https://pytorch.org/docs/master/generated/torch.jit.trace.html\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 1, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "example_forward_input = torch.rand(1, 1, 3, 3)\n",
    "module = torch.jit.trace(net, example_forward_input)\n",
    "\n",
    "# Save the traced model to a file\n",
    "torch.jit.save(module, \"./torch_cnn.pt\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we send the model to the database, again, we assign it a unique key, `tutorial-cnn`, which we will use to refer to the model when using the `Client`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model in the Redis database from the file\n",
    "client.set_model_from_file(\"tutorial-cnn\", \"./torch_cnn.pt\", \"TORCH\", \"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a random tensor, store it on the DB, and use it as input to the CNN we just sent. The `Orchestrator` will run the neural network and store the output with the key we specify. Using that key, we can retrieve the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put a tensor in the database as a test input\n",
    "data = torch.rand(1, 1, 3, 3).numpy()\n",
    "client.put_tensor(\"torch_cnn_input\", data)\n",
    "\n",
    "# Run model and retrieve the output\n",
    "client.run_model(\"tutorial-cnn\", inputs=[\"torch_cnn_input\"], outputs=[\"torch_cnn_output\"])\n",
    "out_data = client.get_tensor(\"torch_cnn_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we could have defined the model as an object (without storing it on disk) and send it to the DB using `set_model` instead of `set_model_from_file`. We can do the same thing for any Python function. For example, let's define a simple function takes a NumPy tensor as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 2. 3. 4. 5. 6. 7. 8.]]\n",
      "Max:\n",
      "8.0\n"
     ]
    }
   ],
   "source": [
    "def max_of_tensor(array):\n",
    "    \"\"\"Sample torchscript script that returns the\n",
    "    highest element in an array.\n",
    "\n",
    "    \"\"\"\n",
    "    # return the highest element\n",
    "    return array.max(1)[0]\n",
    "\n",
    "sample_array_1 = np.array([np.arange(9.)])\n",
    "print(sample_array_1)\n",
    "print(\"Max:\")\n",
    "print(max_of_tensor(sample_array_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's store this function on the DB, assignign it the key `max-of-tensor`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_function(\"max-of-tensor\", max_of_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the same sample computation on the DB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.]\n"
     ]
    }
   ],
   "source": [
    "client.put_tensor(\"script-data-1\", sample_array_1)\n",
    "client.run_script(\n",
    "    \"max-of-tensor\",  # key of our script\n",
    "    \"max_of_tensor\",  # function to be called\n",
    "    [\"script-data-1\"],\n",
    "    [\"script-output\"],\n",
    ")\n",
    "\n",
    "out = client.get_tensor(\"script-output\")\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as expected, we obtain the same result we obtained when we ran the function locally. To clean up, we need to tear down the DB. We do this by stopping the `Orchestrator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:59:29 C02YN0J3JG5M SmartSim[49287] INFO Stopping model orchestrator_0 with job name orchestrator_0-CACWEL8F89TK\n"
     ]
    }
   ],
   "source": [
    "exp.stop(orc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Ensembles using SmartRedis\n",
    "\n",
    "In Section 1.2 we used `Ensemble`s. What would happen if `Model`s which are part of an `Ensemble` tried to put their tensors on the DB using SmartRedis? Unless we used unique keys across the running programs, several tensors (or objects) would have the same key, and this key collision would result in unexpected behavior. In other words, if in the source code of one program, a tensor with key `tensor1` was put on the DB, then each replica of the program would put a tensor with the key `tensor1`. SmartSim and SmartRedis can avoid key collision by prepending program-unique prefixes to entities. \n",
    "\n",
    "Let's start by setting up the experiment with the `Orchestrator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(\"tutorial-smartredis-ensemble\", launcher=\"local\")\n",
    "\n",
    "# create and start a database\n",
    "orc = Orchestrator(port=REDIS_PORT)\n",
    "exp.generate(orc)\n",
    "exp.start(orc, block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add two replicas of the same `Model`. Basically, it is a simple producer, which puts a tensor on the DB. The code for it is in `producer.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_prod = RunSettings(\"python\", \"producer.py --redis-port \"+str(REDIS_PORT))\n",
    "ensemble = exp.create_ensemble(name=\"producer\",\n",
    "                               replicas=2, \n",
    "                               run_settings=rs_prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a consumer, which will just retrieve the tensors put by the two producers and check that they are what it expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_consumer = RunSettings(\"python\", \"consumer.py --redis-port \"+str(REDIS_PORT))\n",
    "consumer = exp.create_model(\"consumer\", run_settings=rs_consumer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to register incoming entities, i.e. entities for which the prefix will have to be known by other entities. When we will start the `Experiment`, environment variables will be set to let all entities know which incoming entities are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.register_incoming_entity(ensemble[0])\n",
    "consumer.register_incoming_entity(ensemble[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we attach the files to the experiments, generate them, and run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:02:07 C02YN0J3JG5M SmartSim[49287] INFO Working in previously created experiment\n",
      "20:02:07 C02YN0J3JG5M SmartSim[49287] INFO Working in previously created experiment\n",
      "\n",
      "\n",
      "\u001b[36;1m=== LAUNCH SUMMARY ===\u001b[0m\n",
      "\u001b[32;1mExperiment: tutorial-smartredis-ensemble\u001b[0m\n",
      "\u001b[32mExperiment Path: /Users/spartee/Dropbox/Cray/smartsim/tutorials/01_getting_started/tutorial-smartredis-ensemble\u001b[0m\n",
      "\u001b[32mLaunching with: local\u001b[0m\n",
      "\u001b[32m# of Ensembles: 1\u001b[0m\n",
      "\u001b[32m# of Models: 1\u001b[0m\n",
      "\u001b[32mDatabase: no\u001b[0m\n",
      "\n",
      "\u001b[36;1m=== ENSEMBLES ===\u001b[0m\n",
      "\u001b[32;1mproducer\u001b[0m\n",
      "\u001b[32m# of models in ensemble: 2\u001b[0m\n",
      "\u001b[32mLaunching as batch: False\u001b[0m\n",
      "\u001b[32mRun Settings: \n",
      "Executable: /Users/spartee/.virtualenvs/smartsim/bin/python\n",
      "Executable arguments: ['producer.py', '--redis-port', '6899']\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[36;1m=== MODELS ===\u001b[0m\n",
      "\u001b[32;1mconsumer\u001b[0m\n",
      "\u001b[32mModel Parameters: \n",
      "{}\u001b[0m\n",
      "\u001b[32mModel Run Settings: \n",
      "Executable: /Users/spartee/.virtualenvs/smartsim/bin/python\n",
      "Executable arguments: ['consumer.py', '--redis-port', '6899']\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:02:22 C02YN0J3JG5M SmartSim[49287] INFO producer_0(68575): Completed\n",
      "20:02:22 C02YN0J3JG5M SmartSim[49287] INFO producer_1(68576): Completed\n",
      "20:02:23 C02YN0J3JG5M SmartSim[49287] INFO consumer(68577): Completed\n",
      "20:02:24 C02YN0J3JG5M SmartSim[49287] INFO consumer(68577): Completed\n"
     ]
    }
   ],
   "source": [
    "ensemble.attach_generator_files(to_copy=['producer.py'])\n",
    "consumer.attach_generator_files(to_copy=['consumer.py'])\n",
    "exp.generate(ensemble, overwrite=True)\n",
    "exp.generate(consumer, overwrite=True)\n",
    "\n",
    "# start the models\n",
    "exp.start(ensemble, consumer, summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The producers produced random NumPy tensors, and we can see that the consumer was able to retrieve both of them from the DB, by looking at its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor for producer_0 is: [[[[0.72651781 0.94967021 0.7009509 ]\n",
      "   [0.12356079 0.10970366 0.17820585]\n",
      "   [0.98406475 0.91311928 0.70532184]]]]\n",
      "Tensor for producer_1 is: [[[[0.99084866 0.56835187 0.19604226]\n",
      "   [0.08345202 0.82443378 0.50058923]\n",
      "   [0.03786348 0.64053919 0.6278744 ]]]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputfile = './tutorial-smartredis-ensemble/consumer/consumer.out'\n",
    "\n",
    "with open(outputfile, 'r') as fin:\n",
    "    print(fin.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's shutdown the DB, by stopping the `Orchestrator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:02:45 C02YN0J3JG5M SmartSim[49287] INFO Stopping model orchestrator_0 with job name orchestrator_0-CACWHRLXI83C\n"
     ]
    }
   ],
   "source": [
    "exp.stop(orc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartsim",
   "language": "python",
   "name": "smartsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
