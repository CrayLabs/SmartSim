

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Online Inference &#8212; SmartSim 0.8.0 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom_tab_style.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script src="../../_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/ml_inference/Inference-in-SmartSim';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Online Training" href="../ml_training/surrogate/train_surrogate.html" />
    <link rel="prev" title="Online Analysis" href="../online_analysis/lattice/online_analysis.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">SmartSim 0.8.0 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../versions.html">Versions</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../overview.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation_instructions/basic.html">Basic Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation_instructions/platform.html">Installation on specific platforms</a></li>








<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../smartsim_zoo.html">Contributing Examples</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../getting_started/getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../online_analysis/lattice/online_analysis.html">Online Analysis</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Online Inference</a></li>

<li class="toctree-l1"><a class="reference internal" href="../ml_training/surrogate/train_surrogate.html">Online Training</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SmartSim</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../experiment.html">Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../run_settings.html">Run Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../batch_settings.html">Batch Settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../model.html">Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ensemble.html">Ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../orchestrator.html">Orchestrator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ss_logger.html">Logger</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../ml_features.html">ML Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../dragon.html">Dragon</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/smartsim_api.html">SmartSim API</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SmartRedis</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../smartredis.html">SmartRedis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sr_integration.html">Integrating into a Simulation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sr_python_walkthrough.html">Python</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sr_cpp_walkthrough.html">C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sr_fortran_walkthrough.html">Fortran</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sr_data_structures.html">Data Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sr_dataset_conversions.html">DataSet Conversions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sr_runtime.html">Runtime Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sr_advanced_topics.html">Advanced Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/smartredis_api.html">SmartRedis API</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SmartDashboard</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../smartdashboard.html">SmartDashboard</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../code_of_conduct.html">Code of Conduct</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer.html">Developer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../testing.html">Testing</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/CrayLabs/SmartSim" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/CrayLabs/SmartSim/issues/new?title=Issue%20on%20page%20%2Ftutorials/ml_inference/Inference-in-SmartSim.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/tutorials/ml_inference/Inference-in-SmartSim.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Online Inference</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Online Inference</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Installing-the-ML-backends">Installing the ML backends</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Starting-the-Database-for-Inference">Starting the Database for Inference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Using-PyTorch">Using PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Using-TorchScript">Using TorchScript</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Setting-TensorFlow-and-Keras-Models">Setting TensorFlow and Keras Models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Using-ONNX">Using ONNX</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Scikit-Learn-K-means-Cluster">Scikit-Learn K-means Cluster</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Scikit-Learn-Random-Forest">Scikit-Learn Random Forest</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Colocated-Deployment">Colocated Deployment</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Online-Inference">
<h1>Online Inference<a class="headerlink" href="#Online-Inference" title="Permalink to this heading">#</a></h1>
<p>This tutorial shows how to use trained PyTorch, TensorFlow, and ONNX (format) models, written in Python, directly in HPC workloads written in Fortran, C, C++ and Python.</p>
<p>The example simulation here is written in Python for brevity, however, the inference API in SmartRedis is the same (besides extra parameters for compiled langauges) across all clients.</p>
<section id="Installing-the-ML-backends">
<h2>Installing the ML backends<a class="headerlink" href="#Installing-the-ML-backends" title="Permalink to this heading">#</a></h2>
<p>In order to use the <code class="docutils literal notranslate"><span class="pre">Orchestrator</span></code> database as an inference engine, the Machine Learning (ML) backends need to be built and supplied to the database at runtime.</p>
<p>To check which backends are built, a simple helper function is available in SmartSim as shown below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Installing the ML backends</span>
<span class="kn">from</span> <span class="nn">smartsim._core.utils.helpers</span> <span class="kn">import</span> <span class="n">installed_redisai_backends</span>
<span class="nb">print</span><span class="p">(</span><span class="n">installed_redisai_backends</span><span class="p">())</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;tensorflow&#39;, &#39;torch&#39;}
</pre></div></div>
</div>
<p>As you can see, only the Torch backend is built. In order to use the TensorFlow and ONNX backends as well, they need to be built.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">smart</span></code> command line interface can be used to build the backends using the <code class="docutils literal notranslate"><span class="pre">smart</span> <span class="pre">build</span></code> command. The output of <code class="docutils literal notranslate"><span class="pre">smart</span> <span class="pre">build</span> <span class="pre">--help</span></code> is shown below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>smart<span class="w"> </span>build<span class="w"> </span>--help
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
usage: smart build [-h] [-v] [--device {cpu,gpu}] [--dragon]
                   [--only_python_packages] [--no_pt] [--no_tf] [--onnx]
                   [--torch_dir TORCH_DIR]
                   [--libtensorflow_dir LIBTENSORFLOW_DIR] [--keydb]
                   [--no_torch_with_mkl]

Build SmartSim dependencies (Redis, RedisAI, Dragon, ML runtimes)

options:
  -h, --help            show this help message and exit
  -v                    Enable verbose build process
  --device {cpu,gpu}    Device to build ML runtimes for
  --dragon              Install the dragon runtime
  --only_python_packages
                        Only evaluate the python packages (i.e. skip building
                        backends)
  --no_pt               Do not build PyTorch backend
  --no_tf               Do not build TensorFlow backend
  --onnx                Build ONNX backend (off by default)
  --torch_dir TORCH_DIR
                        Path to custom &lt;path&gt;/torch/share/cmake/Torch/
                        directory (ONLY USE IF NEEDED)
  --libtensorflow_dir LIBTENSORFLOW_DIR
                        Path to custom libtensorflow directory (ONLY USE IF
                        NEEDED)
  --keydb               Build KeyDB instead of Redis
  --no_torch_with_mkl   Do not build Torch with Intel MKL
</pre></div></div>
</div>
<p>We use <code class="docutils literal notranslate"><span class="pre">smart</span> <span class="pre">clean</span></code> first to remove the previous build, and then call <code class="docutils literal notranslate"><span class="pre">smart</span> <span class="pre">build</span></code> to build the new backend set. For larger teams, CrayLabs will help setup your system so that the backends do not have to be built by each user.</p>
<p>By default, the PyTorch and TensorFlow backends are built. To build all three backends for use on CPU, we issue the following command.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>smart<span class="w"> </span>clean<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>smart<span class="w"> </span>build<span class="w"> </span>--device<span class="w"> </span>cpu<span class="w"> </span>--onnx
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
<span class="ansi-blue-fg">[SmartSim]</span> <span class="ansi-black-intense-fg ansi-bold">INFO</span> Successfully removed existing RedisAI installation
<span class="ansi-blue-fg">[SmartSim]</span> <span class="ansi-black-intense-fg ansi-bold">INFO</span> Successfully removed ML runtimes
<span class="ansi-blue-fg">[SmartSim]</span> <span class="ansi-black-intense-fg ansi-bold">INFO</span> Running SmartSim build process...
<span class="ansi-blue-fg">[SmartSim]</span> <span class="ansi-black-intense-fg ansi-bold">INFO</span> Checking requested versions...
<span class="ansi-blue-fg">[SmartSim]</span> <span class="ansi-black-intense-fg ansi-bold">INFO</span> Redis build complete!

ML Backends Requested
╒════════════╤════════╤══════╕
│ PyTorch    │ 2.1.0  │ <span class="ansi-green-fg">True</span> │
│ TensorFlow │ 2.13.1 │ <span class="ansi-green-fg">True</span> │
│ ONNX       │ 1.14.1 │ <span class="ansi-green-fg">True</span> │
╘════════════╧════════╧══════╛

Building for GPU support: <span class="ansi-red-fg">False</span>

<span class="ansi-blue-fg">[SmartSim]</span> <span class="ansi-black-intense-fg ansi-bold">INFO</span> Building RedisAI version 1.2.7 from https://github.com/RedisAI/RedisAI.git/
<span class="ansi-blue-fg">[SmartSim]</span> <span class="ansi-black-intense-fg ansi-bold">INFO</span> ML Backends and RedisAI build complete!
<span class="ansi-blue-fg">[SmartSim]</span> <span class="ansi-black-intense-fg ansi-bold">INFO</span> Tensorflow, Onnxruntime, Torch backend(s) built
<span class="ansi-blue-fg">[SmartSim]</span> <span class="ansi-black-intense-fg ansi-bold">INFO</span> SmartSim build complete!
</pre></div></div>
</div>
</section>
<section id="Starting-the-Database-for-Inference">
<h2>Starting the Database for Inference<a class="headerlink" href="#Starting-the-Database-for-Inference" title="Permalink to this heading">#</a></h2>
<p>SmartSim performs online inference by using the SmartRedis clients to call into the Machine Learning (ML) runtimes linked into the Orchestrator database. The Orchestrator is the name in SmartSim for a Redis or KeyDB database with a RedisAI module built into it with the ML runtimes.</p>
<p>Therefore, to perform inference, you must first create an Orchestrator database and launch it. There are two methods to couple the database to your application in order to add inference capability to your application. - standard (not colocated) - colocated</p>
<p><code class="docutils literal notranslate"><span class="pre">standard</span></code> mode launches an optionally clustered (across many compute hosts) database instance that can be treated as a single storage device for many clients (possibly the many ranks of an MPI program) where there is a single address space for keys across all hosts.</p>
<p><code class="docutils literal notranslate"><span class="pre">colocated</span></code> mode launches a orchestrator instance on each compute host used by a, possibly distributed, application. each instance contains their own address space for keys. In SmartSim, <code class="docutils literal notranslate"><span class="pre">Model</span></code> instances can be launched with a colocated orchetrator through <code class="docutils literal notranslate"><span class="pre">Model.colocate_db_tcp</span></code> or <code class="docutils literal notranslate"><span class="pre">Model.colocate_db_udp</span></code>. Colocated <code class="docutils literal notranslate"><span class="pre">Model</span></code>s are used for highly scalable inference where global aggregations aren’t necessary for inference.</p>
<p>The code below launches the <code class="docutils literal notranslate"><span class="pre">Orchestrator</span></code> database using the <code class="docutils literal notranslate"><span class="pre">standard</span></code> deployment method.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># some helper libraries for the tutorial</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;3&#39;</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># import smartsim and smartredis</span>
<span class="kn">from</span> <span class="nn">smartredis</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="kn">from</span> <span class="nn">smartsim</span> <span class="kn">import</span> <span class="n">Experiment</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span> <span class="o">=</span> <span class="n">Experiment</span><span class="p">(</span><span class="s2">&quot;Inference-Tutorial&quot;</span><span class="p">,</span> <span class="n">launcher</span><span class="o">=</span><span class="s2">&quot;local&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">db</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">create_database</span><span class="p">(</span><span class="n">port</span><span class="o">=</span><span class="mi">6780</span><span class="p">,</span> <span class="n">interface</span><span class="o">=</span><span class="s2">&quot;lo&quot;</span><span class="p">)</span>
<span class="n">exp</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">db</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
</section>
<section id="Using-PyTorch">
<h2>Using PyTorch<a class="headerlink" href="#Using-PyTorch" title="Permalink to this heading">#</a></h2>
<p>The Orchestrator supports both <a class="reference external" href="https://pytorch.org/">PyTorch</a> models and <a class="reference external" href="https://pytorch.org/docs/stable/jit.html">TorchScript</a> functions and scripts in PyTorch.</p>
<p>Below, the code is shown to create, jit-trace (prepare for inference), set, and call a PyTorch Convolutional Neural Network (CNN) with SmartSim and SmartRedis</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.25</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">9216</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>
<br/></pre></div>
</div>
</div>
<p>To set a PyTorch model, we create a function to “jit-trace” the model and save it to a buffer in memory.</p>
<p>If you aren’t familiar with the concept of tracing, take a look at the Torch documentation for <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html#torch.jit.trace">trace</a></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize an instance of our CNN model</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">n</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># prepare a sample input to trace on (random noise is fine)</span>
<span class="n">example_forward_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_torch_model</span><span class="p">(</span><span class="n">torch_module</span><span class="p">,</span> <span class="n">example_forward_input</span><span class="p">):</span>

    <span class="c1"># perform the trace of the nn.Module.forward() method</span>
    <span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">torch_module</span><span class="p">,</span> <span class="n">example_forward_input</span><span class="p">)</span>

    <span class="c1"># save the traced module to a buffer</span>
    <span class="n">model_buffer</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">()</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">jit</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">model_buffer</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model_buffer</span><span class="o">.</span><span class="n">getvalue</span><span class="p">()</span>

<span class="n">traced_cnn</span> <span class="o">=</span> <span class="n">create_torch_model</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">example_forward_input</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<p>Lastly, we use the SmartRedis Python client to</p>
<ol class="arabic simple">
<li><p>Connect to the database</p></li>
<li><p>Put a batch of 20 tensors into the database (<code class="docutils literal notranslate"><span class="pre">put_tensor</span></code>)</p></li>
<li><p>Set the Torch model in the database (<code class="docutils literal notranslate"><span class="pre">set_model</span></code>)</p></li>
<li><p>Run the model on the batch of tensors (<code class="docutils literal notranslate"><span class="pre">run_model</span></code>)</p></li>
<li><p>Retrieve the result (<code class="docutils literal notranslate"><span class="pre">get_tensor</span></code>)</p></li>
</ol>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">address</span><span class="o">=</span><span class="n">db</span><span class="o">.</span><span class="n">get_address</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cluster</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="c1"># put the PyTorch CNN in the database in GPU memory</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="s2">&quot;cnn&quot;</span><span class="p">,</span> <span class="n">traced_cnn</span><span class="p">,</span> <span class="s2">&quot;TORCH&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>

<span class="c1"># execute the model, supports a variable number of inputs and outputs</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;cnn&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">],</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">])</span>

<span class="c1"># get the output</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction: </span><span class="si">{</span><span class="n">output</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Prediction: [[-2.2239347 -2.256488  -2.3910825 -2.2572591 -2.2663934 -2.3775585
  -2.257742  -2.3160243 -2.391289  -2.3055189]
 [-2.2149696 -2.2576108 -2.3899908 -2.2715292 -2.2628417 -2.3693023
  -2.260772  -2.3166935 -2.3967428 -2.3028378]
 [-2.2214003 -2.2581112 -2.3854284 -2.2616909 -2.2745335 -2.3779867
  -2.2570336 -2.3125517 -2.391247  -2.302534 ]
 [-2.214657  -2.2598932 -2.3800194 -2.2612374 -2.2718334 -2.3784144
  -2.2596886 -2.318937  -2.3904119 -2.3075597]
 [-2.2034936 -2.2570574 -2.4026587 -2.2698882 -2.2597382 -2.3796346
  -2.2662714 -2.3141642 -2.3986044 -2.2949069]
 [-2.2162325 -2.2635622 -2.3800213 -2.2569213 -2.264393  -2.3763664
  -2.2658355 -2.3211577 -2.3904028 -2.307555 ]
 [-2.2084794 -2.258525  -2.393487  -2.26341   -2.2674217 -2.3792422
  -2.264515  -2.3262923 -2.3823283 -2.300095 ]
 [-2.2175536 -2.2577217 -2.3975415 -2.2582505 -2.269493  -2.365971
  -2.2619228 -2.3258338 -2.3984828 -2.291332 ]
 [-2.2151139 -2.2522063 -2.3931108 -2.2577128 -2.270789  -2.371976
  -2.2567465 -2.32229   -2.395818  -2.308673 ]
 [-2.2141316 -2.2494154 -2.3948152 -2.2606037 -2.2732735 -2.3758345
  -2.2620056 -2.3184063 -2.385798  -2.3094575]
 [-2.221041  -2.2519057 -2.398841  -2.259931  -2.2686832 -2.3660865
  -2.2632158 -2.322879  -2.3970191 -2.2942836]
 [-2.2142313 -2.2578502 -2.393603  -2.2673647 -2.2553272 -2.37376
  -2.2617526 -2.3199627 -2.399065  -2.301728 ]
 [-2.2082942 -2.2571995 -2.3889875 -2.266007  -2.257706  -2.37675
  -2.266374  -2.3223817 -2.3961644 -2.304737 ]
 [-2.2229445 -2.2658186 -2.399095  -2.2566628 -2.266294  -2.3742397
  -2.2578638 -2.3047974 -2.3973055 -2.2988966]
 [-2.215887  -2.2676513 -2.3889093 -2.246127  -2.266115  -2.3842902
  -2.2586591 -2.3106883 -2.396018  -2.3104343]
 [-2.2099977 -2.2719226 -2.391469  -2.255561  -2.266949  -2.371345
  -2.2596216 -2.324484  -2.3890057 -2.3031068]
 [-2.214121  -2.2561312 -2.391877  -2.261881  -2.2639613 -2.3679278
  -2.269122  -2.3139405 -2.4036062 -2.3015296]
 [-2.22871   -2.256755  -2.3881361 -2.2651346 -2.2651856 -2.3733103
  -2.2641761 -2.3182902 -2.3855858 -2.2960906]
 [-2.2103846 -2.2450664 -2.3848588 -2.2795632 -2.2658024 -2.3679922
  -2.2666745 -2.3190453 -2.3987417 -2.3054008]
 [-2.2175698 -2.2573788 -2.391653  -2.2519581 -2.2637622 -2.3839104
  -2.265371  -2.3158426 -2.3929882 -2.3040662]]
</pre></div></div>
</div>
<p>As we gave the CNN random noise, the predictions reflect that.</p>
<p>If running on GPU, be sure to change the argument in the <code class="docutils literal notranslate"><span class="pre">set_model</span></code> call above to <code class="docutils literal notranslate"><span class="pre">device=&quot;GPU&quot;</span></code>.</p>
</section>
<section id="Using-TorchScript">
<h2>Using TorchScript<a class="headerlink" href="#Using-TorchScript" title="Permalink to this heading">#</a></h2>
<p>In addition to PyTorch models, TorchScript scripts and functions can be set in the Orchestrator database and called from any of the SmartRedis languages. Functions can be set in the database in Python prior to application launch and then used directly in Fortran, C, and C++ simulations.</p>
<p>The example below uses the TorchScript Singular Value Decomposition (SVD) function. The function set in side the database and then called with a random input tensor.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calc_svd</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">):</span>
    <span class="c1"># svd function from TorchScript API</span>
    <span class="k">return</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">svd</span><span class="p">()</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># connect a client to the database</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">address</span><span class="o">=</span><span class="n">db</span><span class="o">.</span><span class="n">get_address</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cluster</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># test the SVD function</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_function</span><span class="p">(</span><span class="s2">&quot;svd&quot;</span><span class="p">,</span> <span class="n">calc_svd</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_script</span><span class="p">(</span><span class="s2">&quot;svd&quot;</span><span class="p">,</span> <span class="s2">&quot;calc_svd&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;U&quot;</span><span class="p">,</span> <span class="s2">&quot;S&quot;</span><span class="p">,</span> <span class="s2">&quot;V&quot;</span><span class="p">])</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;U&quot;</span><span class="p">)</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;S&quot;</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;V&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;U: </span><span class="si">{</span><span class="n">U</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">, S: </span><span class="si">{</span><span class="n">S</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">, V: </span><span class="si">{</span><span class="n">V</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
U: [[[-0.50057614  0.2622205 ]
  [-0.47629714 -0.8792326 ]
  [-0.7228863   0.39773142]]

 [[-0.45728168  0.88121146]
  [-0.37974676 -0.31532544]
  [-0.80416775 -0.35218775]]

 [[-0.4667158   0.8836199 ]
  [-0.47055572 -0.21237665]
  [-0.7488349  -0.4172673 ]]

 [[-0.32159734  0.92966324]
  [-0.6941528  -0.10238242]
  [-0.64399314 -0.35389856]]

 [[-0.6984835   0.4685579 ]
  [-0.55331963  0.12572214]
  [-0.45382637 -0.8744412 ]]]

, S: [[164.58028    49.682358 ]
 [120.11677    66.62553  ]
 [130.01929    17.520935 ]
 [198.615      22.047113 ]
 [154.67653     2.6773496]]

, V: [[[-0.7275351  -0.68607044]
  [-0.68607044  0.7275351 ]]

 [[-0.6071297   0.79460275]
  [-0.79460275 -0.6071297 ]]

 [[-0.604189    0.7968411 ]
  [-0.7968411  -0.604189  ]]

 [[-0.69911253 -0.7150117 ]
  [-0.7150117   0.69911253]]

 [[-0.8665945  -0.499013  ]
  [-0.499013    0.8665945 ]]]

</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## TensorFlow and Keras</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="n">tf</span><span class="o">.</span><span class="n">get_logger</span><span class="p">()</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>

<span class="c1"># create a simple Fully connected network in Keras</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">layers</span><span class="o">=</span><span class="p">[</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">InputLayer</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;flatten&quot;</span><span class="p">),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;dense&quot;</span><span class="p">),</span>
        <span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;FCN&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Compile model with optimizer</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;sparse_categorical_crossentropy&quot;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>
<br/></pre></div>
</div>
</div>
<section id="Setting-TensorFlow-and-Keras-Models">
<h3>Setting TensorFlow and Keras Models<a class="headerlink" href="#Setting-TensorFlow-and-Keras-Models" title="Permalink to this heading">#</a></h3>
<p>After a model is created (trained or not), the graph of the model is frozen and saved to file so the client method <code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code> can load it into the database.</p>
<p>SmartSim includes a utility to freeze the graph of a TensorFlow or Keras model in <code class="docutils literal notranslate"><span class="pre">smartsim.ml.tf</span></code>. To use TensorFlow or Keras in SmartSim, specify <code class="docutils literal notranslate"><span class="pre">TF</span></code> as the argument for <em>backend</em> in the call to <code class="docutils literal notranslate"><span class="pre">client.set_model</span></code> or <code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code>.</p>
<p>Note that TensorFlow and Keras, unlike the other ML libraries supported by SmartSim, requires an <code class="docutils literal notranslate"><span class="pre">input</span></code> and <code class="docutils literal notranslate"><span class="pre">output</span></code> argument in the call to <code class="docutils literal notranslate"><span class="pre">set_model</span></code>. These arguments correspond to the layer names of the created model. The <code class="docutils literal notranslate"><span class="pre">smartsim.ml.tf.freeze_model</span></code> utility returns these values for convenience as shown below.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">smartsim.ml.tf</span> <span class="kn">import</span> <span class="n">freeze_model</span>

<span class="c1"># SmartSim utility for Freezing the model and saving it to a file.</span>
<span class="n">model_path</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">freeze_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">(),</span> <span class="s2">&quot;fcn.pb&quot;</span><span class="p">)</span>

<span class="c1"># use the same client we used for PyTorch to set the TensorFlow model</span>
<span class="c1"># this time the method for setting a model from a saved file is shown.</span>
<span class="c1"># TensorFlow backed requires named inputs and outputs on graph</span>
<span class="c1"># this differs from PyTorch and ONNX.</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_model_from_file</span><span class="p">(</span>
    <span class="s2">&quot;keras_fcn&quot;</span><span class="p">,</span> <span class="n">model_path</span><span class="p">,</span> <span class="s2">&quot;TF&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span>
<span class="p">)</span>

<span class="c1"># put random random input tensor into the database</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">input_data</span><span class="p">)</span>

<span class="c1"># run the Fully Connected Network model on the tensor we just put</span>
<span class="c1"># in and store the result of the inference at the &quot;output&quot; key</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;keras_fcn&quot;</span><span class="p">,</span> <span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;output&quot;</span><span class="p">)</span>

<span class="c1"># get the result of the inference</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[0.06595241 0.11921222 0.02889561 0.20963618 0.08950416 0.11298887
  0.05179482 0.09778847 0.14826407 0.07596324]]
</pre></div></div>
</div>
</section>
</section>
<section id="Using-ONNX">
<h2>Using ONNX<a class="headerlink" href="#Using-ONNX" title="Permalink to this heading">#</a></h2>
<p>ONNX is a standard format for representing models. A number of different Machine Learning Libraries are supported by ONNX and can be readily used with SmartSim.</p>
<p>Some popular ones are:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://scikit-learn.org">Scikit-learn</a></p></li>
<li><p><a class="reference external" href="https://xgboost.readthedocs.io">XGBoost</a></p></li>
<li><p><a class="reference external" href="https://catboost.ai">CatBoost</a></p></li>
<li><p><a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/">LightGBM</a></p></li>
<li><p><a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/">libsvm</a></p></li>
</ul>
<p>As well as some that are not listed. There are also many tools to help convert models to ONNX.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/onnx/onnxmltools">onnxmltools</a></p></li>
<li><p><a class="reference external" href="https://github.com/onnx/sklearn-onnx/">skl2onnx</a></p></li>
<li><p><a class="reference external" href="https://github.com/onnx/tensorflow-onnx/">tensorflow-onnx</a></p></li>
</ul>
<p>And PyTorch has its own converter.</p>
<p>Below are some examples of a few models in <a class="reference external" href="https://scikit-learn.org">Scikit-learn</a> that are converted into ONNX format for use with SmartSim. To use ONNX in SmartSim, specify <code class="docutils literal notranslate"><span class="pre">ONNX</span></code> as the argument for <em>backend</em> in the call to <code class="docutils literal notranslate"><span class="pre">client.set_model</span></code> or <code class="docutils literal notranslate"><span class="pre">client.set_model_from_file</span></code></p>
<section id="Scikit-Learn-K-means-Cluster">
<h3>Scikit-Learn K-means Cluster<a class="headerlink" href="#Scikit-Learn-K-means-Cluster" title="Permalink to this heading">#</a></h3>
<p>K-means clustering is an unsupervised ML algorithm. It is used to categorize data points into functional groups (“clusters”). Scikit Learn has a built in implementation of K-means clustering and it is easily converted to ONNX for use with SmartSim through <a class="reference external" href="http://onnx.ai/sklearn-onnx/auto_examples/plot_convert_syntax.html">skl2onnx.to_onnx</a></p>
<p>Since the KMeans model returns two outputs, we provide the <code class="docutils literal notranslate"><span class="pre">client.run_model</span></code> call with two <code class="docutils literal notranslate"><span class="pre">output</span></code> key names.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">skl2onnx</span> <span class="kn">import</span> <span class="n">to_onnx</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">tr</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">tr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># save the trained k-means model in memory with skl2onnx</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">tr</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">target_opset</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>

<span class="c1"># random input data</span>
<span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># use the same client from TensorFlow and Pytorch examples.</span>
<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="s2">&quot;kmeans&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;ONNX&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;kmeans&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">,</span> <span class="s2">&quot;transform&quot;</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;labels&quot;</span><span class="p">))</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Default@[0 0 0 0 0 1 1 1 1 1]
</pre></div></div>
</div>
</section>
<section id="Scikit-Learn-Random-Forest">
<h3>Scikit-Learn Random Forest<a class="headerlink" href="#Scikit-Learn-Random-Forest" title="Permalink to this heading">#</a></h3>
<p>The Random Forest example uses the Iris dataset from Scikit Learn to train a RandomForestRegressor. As with the other examples, the skl2onnx function <code class="docutils literal notranslate"><span class="pre">skl2onnx.to_onnx</span></code> is used to convert the model to ONNX format.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>
<span class="n">clr</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">clr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">rf_model</span> <span class="o">=</span> <span class="n">to_onnx</span><span class="p">(</span><span class="n">clr</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">target_opset</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">6.4</span><span class="p">,</span> <span class="mf">2.8</span><span class="p">,</span> <span class="mf">5.6</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">]])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">rf_model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>

<span class="n">client</span><span class="o">.</span><span class="n">put_tensor</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">sample</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="s2">&quot;rf_regressor&quot;</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="s2">&quot;ONNX&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
<span class="n">client</span><span class="o">.</span><span class="n">run_model</span><span class="p">(</span><span class="s2">&quot;rf_regressor&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="s2">&quot;output&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">client</span><span class="o">.</span><span class="n">get_tensor</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">))</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[[1.9999987]]
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="n">db</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;html&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>  </th><th>Name          </th><th>Entity-Type  </th><th>JobID  </th><th>RunID  </th><th>Time   </th><th>Status                         </th><th>Returncode  </th></tr>
</thead>
<tbody>
<tr><td>0 </td><td>orchestrator_0</td><td>DBNode       </td><td>2809   </td><td>0      </td><td>70.9690</td><td>SmartSimStatus.STATUS_CANCELLED</td><td>0           </td></tr>
</tbody>
</table></div>
</div>
</section>
</section>
</section>
<section id="Colocated-Deployment">
<h1>Colocated Deployment<a class="headerlink" href="#Colocated-Deployment" title="Permalink to this heading">#</a></h1>
<p>A colocated Orchestrator is a special type of Orchestrator that is deployed on the same compute hosts an a Model instance defined by the user. In this deployment, the database is not connected together in a cluster and each shard of the database is addressed individually by the processes running on that compute host. This is particularly important for GPU-intensive workloads which require frequent communication with the database.</p>
<center><p><img alt="lattice" class="no-scaled-link" src="https://www.craylabs.org/docs/_images/colocated_orchestrator-1.png" style="width: 600px;" /></p>
</center><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create colocated model</span>
<span class="n">colo_settings</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">create_run_settings</span><span class="p">(</span>
    <span class="n">exe</span><span class="o">=</span><span class="s2">&quot;python&quot;</span><span class="p">,</span>
    <span class="n">exe_args</span><span class="o">=</span><span class="s2">&quot;./colo-db-torch-example.py&quot;</span>
<span class="p">)</span>

<span class="n">colo_model</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">create_model</span><span class="p">(</span><span class="s2">&quot;colocated_model&quot;</span><span class="p">,</span> <span class="n">colo_settings</span><span class="p">)</span>
<span class="n">colo_model</span><span class="o">.</span><span class="n">colocate_db_tcp</span><span class="p">(</span>
    <span class="n">port</span><span class="o">=</span><span class="mi">6780</span><span class="p">,</span>
    <span class="n">db_cpus</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">ifname</span><span class="o">=</span><span class="s2">&quot;lo&quot;</span>
<span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">colo_model</span><span class="p">,</span> <span class="n">summary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
19:30:35 HPE-C02YR4ANLVCJ SmartSim[1187:MainThread] INFO

=== Launch Summary ===
Experiment: Inference-Tutorial
Experiment Path: /home/craylabs/tutorials/ml_inference/Inference-Tutorial
Launcher: local
Models: 1
Database Status: inactive

=== Models ===
colocated_model
Executable: /usr/local/anaconda3/envs/ss-py3.10/bin/python
Executable Arguments: ./colo-db-torch-example.py
Co-located Database: True



19:30:38 HPE-C02YR4ANLVCJ SmartSim[1187:JobManager] WARNING colocated_model(3199): SmartSimStatus.STATUS_FAILED
19:30:38 HPE-C02YR4ANLVCJ SmartSim[1187:JobManager] WARNING colocated_model failed. See below for details
Job status at failure: SmartSimStatus.STATUS_FAILED
Launcher status at failure: Failed
Job returncode: 2
Error and output file located at: /home/craylabs/tutorials/ml_inference/Inference-Tutorial/colocated_model
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">exp</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;html&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>  </th><th>Name           </th><th>Entity-Type  </th><th>JobID  </th><th>RunID  </th><th>Time   </th><th>Status                         </th><th>Returncode  </th></tr>
</thead>
<tbody>
<tr><td>0 </td><td>orchestrator_0 </td><td>DBNode       </td><td>2809   </td><td>0      </td><td>70.9690</td><td>SmartSimStatus.STATUS_CANCELLED</td><td>0           </td></tr>
<tr><td>1 </td><td>colocated_model</td><td>Model        </td><td>3199   </td><td>0      </td><td>3.1599 </td><td>SmartSimStatus.STATUS_FAILED   </td><td>2           </td></tr>
</tbody>
</table></div>
</div>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../online_analysis/lattice/online_analysis.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Online Analysis</p>
      </div>
    </a>
    <a class="right-next"
       href="../ml_training/surrogate/train_surrogate.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Online Training</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Online Inference</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Installing-the-ML-backends">Installing the ML backends</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Starting-the-Database-for-Inference">Starting the Database for Inference</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Using-PyTorch">Using PyTorch</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Using-TorchScript">Using TorchScript</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Setting-TensorFlow-and-Keras-Models">Setting TensorFlow and Keras Models</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Using-ONNX">Using ONNX</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Scikit-Learn-K-means-Cluster">Scikit-Learn K-means Cluster</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Scikit-Learn-Random-Forest">Scikit-Learn Random Forest</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Colocated-Deployment">Colocated Deployment</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Cray Labs
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2021-2024, Hewlett Packard Enterprise.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
<div class="extra_footer">
  Questions? You can contact <a href="mailto:craylabs@hpe.com">contact us</a> or <a href="https://join.slack.com/t/craylabs/shared_invite/zt-nw3ag5z5-5PS4tIXBfufu1bIvvr71UA">join us on Slack!</a>
</div>
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>