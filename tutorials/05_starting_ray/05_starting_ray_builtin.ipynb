{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42905082",
   "metadata": {},
   "source": [
    "# Setting up a Ray cluster with SmartSim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc796b",
   "metadata": {},
   "source": [
    "## 1. Start the cluster\n",
    "We set up a SmartSim experiment, which will handle the launch of the Ray cluster.\n",
    "\n",
    "First we import the relevant modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c17fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from ray.tune.progress_reporter import JupyterNotebookReporter\n",
    "import ray\n",
    "from ray import tune\n",
    "import ray.util\n",
    "\n",
    "from smartsim import Experiment\n",
    "from smartsim.ray import RayCluster\n",
    "\n",
    "NUM_WORKERS = 3\n",
    "alloc=None\n",
    "#alloc=slurm.get_allocation(nodes=1+NUM_WORKERS, time=\"12:00:00\", options={\"ntasks\": str(1+NUM_WORKERS), \"partition\": \"spider\", \"C\": \"V100\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a69118",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executable: /lus/scratch/arigazzi/anaconda3/envs/smartsim/bin/python\n",
      "Executable arguments: ['/lus/scratch/arigazzi/smartsim-dev/SmartSim/smartsim/ray/raystarter.py', '--num-cpus=18', '--port=6780', '--redis-password=cb2af36a-7d31-492b-a822-f895a9d426df']\n",
      "Run Command: aprun\n",
      "Run arguments: {'sync-output': None}\n",
      "07:49:02 swan SmartSim[9468] INFO Working in previously created experiment\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment(\"ray-cluster\", launcher='pbs')\n",
    "cluster = RayCluster(name=\"ray-cluster\", run_args={}, path='',\n",
    "                     launcher='pbs', workers=NUM_WORKERS, alloc=alloc, batch=True, ray_num_cpus=18)\n",
    "\n",
    "if cluster.batch:\n",
    "    cluster.head_model.batch_settings._preamble += [\"source ~/.bashrc\", \"conda activate smartsim\"]\n",
    "    if NUM_WORKERS:\n",
    "        cluster.worker_model.batch_settings._preamble += [\"source ~/.bashrc\", \"conda activate smartsim\"]\n",
    "\n",
    "exp.generate(cluster, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b255fa37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07:49:27 swan SmartSim[9468] DEBUG Added step command to batch for head-CBLHL6YRZQ0B\n",
      "07:49:27 swan SmartSim[9468] DEBUG Gleaned batch job id: 37800.sdb for head-CBLHL6YRZ3P9\n",
      "07:49:27 swan SmartSim[9468] DEBUG Launching head\n",
      "07:49:41 swan SmartSim[9468] DEBUG WLM Ray head node acquisition unsupported\n",
      "07:49:41 swan SmartSim[9468] DEBUG Added step command to batch for workers-CBLHLDHBME4H\n",
      "07:49:41 swan SmartSim[9468] DEBUG Gleaned batch job id: 37801.sdb for workers-CBLHLDHBLATC\n",
      "07:49:41 swan SmartSim[9468] DEBUG Launching workers\n",
      "07:49:41 swan SmartSim[9468] DEBUG WLM Ray worker node acquisition unsupported\n",
      "07:49:41 swan SmartSim[9468] INFO Ray cluster launched.\n",
      "07:49:41 swan SmartSim[9468] DEBUG Starting Job Manager\n"
     ]
    }
   ],
   "source": [
    "exp.start(cluster, block=False, summary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af6be4",
   "metadata": {},
   "source": [
    "## 2. Start the ray driver script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68019ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 5.0/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 3.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (49 PENDING, 1 RUNNING)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 5.4/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 18.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (44 PENDING, 6 RUNNING)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74676)\u001b[0m 2021-05-24 07:53:58,592\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=74672)\u001b[0m 2021-05-24 07:53:58,821\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=74674)\u001b[0m 2021-05-24 07:53:58,835\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=74670)\u001b[0m 2021-05-24 07:53:59,145\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=74667)\u001b[0m 2021-05-24 07:53:59,225\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=74665)\u001b[0m 2021-05-24 07:53:59,355\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=74670)\u001b[0m 2021-05-24 07:54:32,726\tINFO trainable.py:101 -- Trainable.setup took 33.581 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=74667)\u001b[0m 2021-05-24 07:54:32,712\tINFO trainable.py:101 -- Trainable.setup took 33.487 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=74672)\u001b[0m 2021-05-24 07:54:32,766\tINFO trainable.py:101 -- Trainable.setup took 33.948 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=74674)\u001b[0m 2021-05-24 07:54:32,754\tINFO trainable.py:101 -- Trainable.setup took 33.919 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=74665)\u001b[0m 2021-05-24 07:54:32,739\tINFO trainable.py:101 -- Trainable.setup took 33.384 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=74676)\u001b[0m 2021-05-24 07:54:32,795\tINFO trainable.py:101 -- Trainable.setup took 34.203 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.6/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 18.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (44 PENDING, 6 RUNNING)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.6/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (26 PENDING, 24 RUNNING)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=61437)\u001b[0m 2021-05-24 07:56:07,687\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=61519)\u001b[0m 2021-05-24 07:56:07,691\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=61507)\u001b[0m 2021-05-24 07:56:07,685\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=61536)\u001b[0m 2021-05-24 07:56:07,678\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=61545)\u001b[0m 2021-05-24 07:56:07,683\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=61571)\u001b[0m 2021-05-24 07:56:07,680\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=86547)\u001b[0m 2021-05-24 07:56:07,684\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=86599)\u001b[0m 2021-05-24 07:56:07,681\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=29270)\u001b[0m 2021-05-24 07:56:07,677\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=86629)\u001b[0m 2021-05-24 07:56:07,688\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=86648)\u001b[0m 2021-05-24 07:56:07,679\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=86667)\u001b[0m 2021-05-24 07:56:07,686\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=29343)\u001b[0m 2021-05-24 07:56:07,682\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=86690)\u001b[0m 2021-05-24 07:56:07,690\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=29356)\u001b[0m 2021-05-24 07:56:07,691\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=29379)\u001b[0m 2021-05-24 07:56:07,684\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=29393)\u001b[0m 2021-05-24 07:56:07,688\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=29416)\u001b[0m 2021-05-24 07:56:07,678\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=29416)\u001b[0m 2021-05-24 07:56:22,365\tINFO trainable.py:101 -- Trainable.setup took 14.689 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=61571)\u001b[0m 2021-05-24 07:56:22,433\tINFO trainable.py:101 -- Trainable.setup took 14.755 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=86547)\u001b[0m 2021-05-24 07:56:22,444\tINFO trainable.py:101 -- Trainable.setup took 14.760 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=86648)\u001b[0m 2021-05-24 07:56:22,429\tINFO trainable.py:101 -- Trainable.setup took 14.751 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=86667)\u001b[0m 2021-05-24 07:56:22,453\tINFO trainable.py:101 -- Trainable.setup took 14.767 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=61507)\u001b[0m 2021-05-24 07:56:22,452\tINFO trainable.py:101 -- Trainable.setup took 14.772 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=61545)\u001b[0m 2021-05-24 07:56:22,470\tINFO trainable.py:101 -- Trainable.setup took 14.792 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=86599)\u001b[0m 2021-05-24 07:56:22,489\tINFO trainable.py:101 -- Trainable.setup took 14.808 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=86629)\u001b[0m 2021-05-24 07:56:22,503\tINFO trainable.py:101 -- Trainable.setup took 14.817 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=86690)\u001b[0m 2021-05-24 07:56:22,473\tINFO trainable.py:101 -- Trainable.setup took 14.783 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=61519)\u001b[0m 2021-05-24 07:56:22,585\tINFO trainable.py:101 -- Trainable.setup took 14.894 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=29270)\u001b[0m 2021-05-24 07:56:22,750\tINFO trainable.py:101 -- Trainable.setup took 15.074 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=61536)\u001b[0m 2021-05-24 07:56:22,797\tINFO trainable.py:101 -- Trainable.setup took 15.119 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=29343)\u001b[0m 2021-05-24 07:56:22,856\tINFO trainable.py:101 -- Trainable.setup took 15.174 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=61437)\u001b[0m 2021-05-24 07:56:22,877\tINFO trainable.py:101 -- Trainable.setup took 15.189 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=29379)\u001b[0m 2021-05-24 07:56:22,881\tINFO trainable.py:101 -- Trainable.setup took 15.199 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=29393)\u001b[0m 2021-05-24 07:56:22,975\tINFO trainable.py:101 -- Trainable.setup took 15.288 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=29356)\u001b[0m 2021-05-24 07:56:23,169\tINFO trainable.py:101 -- Trainable.setup took 15.479 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.6/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (26 PENDING, 23 RUNNING, 1 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.5/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (25 PENDING, 23 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:17,627\tWARNING util.py:161 -- The `start_trial` operation took 0.516 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.6/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (24 PENDING, 24 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.8/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (24 PENDING, 24 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:35,432\tWARNING util.py:161 -- The `callbacks.on_trial_result` operation took 0.632 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:35,433\tWARNING util.py:161 -- The `process_trial_result` operation took 0.634 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:35,433\tWARNING util.py:161 -- Processing trial results took 0.634 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:35,433\tWARNING util.py:161 -- The `process_trial` operation took 0.634 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:35,995\tWARNING util.py:161 -- The `callbacks.on_trial_result` operation took 0.556 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:35,996\tWARNING util.py:161 -- The `process_trial_result` operation took 0.558 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:35,996\tWARNING util.py:161 -- Processing trial results took 0.558 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:35,996\tWARNING util.py:161 -- The `process_trial` operation took 0.558 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:36,579\tWARNING util.py:161 -- The `callbacks.on_trial_result` operation took 0.576 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:36,580\tWARNING util.py:161 -- The `process_trial_result` operation took 0.578 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:36,580\tWARNING util.py:161 -- Processing trial results took 0.578 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:36,580\tWARNING util.py:161 -- The `process_trial` operation took 0.579 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:37,217\tWARNING util.py:161 -- The `callbacks.on_trial_result` operation took 0.632 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:37,219\tWARNING util.py:161 -- The `process_trial_result` operation took 0.634 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:37,219\tWARNING util.py:161 -- Processing trial results took 0.634 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:57:37,219\tWARNING util.py:161 -- The `process_trial` operation took 0.635 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.4/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (24 PENDING, 24 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=77710)\u001b[0m 2021-05-24 07:57:51,084\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=77712)\u001b[0m 2021-05-24 07:57:51,081\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=77710)\u001b[0m 2021-05-24 07:58:25,382\tINFO trainable.py:101 -- Trainable.setup took 34.298 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=77712)\u001b[0m 2021-05-24 07:58:25,393\tINFO trainable.py:101 -- Trainable.setup took 34.312 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (24 PENDING, 24 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (24 PENDING, 24 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (22 PENDING, 24 RUNNING, 4 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (22 PENDING, 23 RUNNING, 5 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 5.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (19 PENDING, 23 RUNNING, 8 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 07:59:25,828\tWARNING util.py:161 -- The `start_trial` operation took 0.563 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=31977)\u001b[0m 2021-05-24 07:59:28,301\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=64181)\u001b[0m 2021-05-24 07:59:30,299\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=31977)\u001b[0m 2021-05-24 07:59:39,929\tINFO trainable.py:101 -- Trainable.setup took 11.628 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=64181)\u001b[0m 2021-05-24 07:59:42,528\tINFO trainable.py:101 -- Trainable.setup took 12.229 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=79720)\u001b[0m 2021-05-24 07:59:48,995\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=79722)\u001b[0m 2021-05-24 07:59:49,103\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=79726)\u001b[0m 2021-05-24 07:59:49,264\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=79731)\u001b[0m 2021-05-24 07:59:49,286\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.5/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (18 PENDING, 24 RUNNING, 8 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.8/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (18 PENDING, 23 RUNNING, 9 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:00:03,838\tWARNING util.py:161 -- The `start_trial` operation took 0.822 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:00:07,417\tWARNING util.py:161 -- The `start_trial` operation took 0.626 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:00:08,196\tWARNING util.py:161 -- The `start_trial` operation took 0.646 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 7.3/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (15 PENDING, 24 RUNNING, 11 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:00:11,217\tWARNING util.py:161 -- The `start_trial` operation took 0.684 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:00:12,178\tWARNING util.py:161 -- The `start_trial` operation took 0.809 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 7.5/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (13 PENDING, 23 RUNNING, 14 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The actor or task with ID fffffffffffffffff37ac4a84fb0183e6290f1a301000000 cannot be scheduled right now. It requires {CPU_group_0_37ac7e201c3d77d338995747f50fd7c8: 1.000000}, {CPU_group_37ac7e201c3d77d338995747f50fd7c8: 1.000000} for placement, but this node only has remaining {0.000000/18.000000 CPU, 87.214506 GiB/87.214506 GiB memory, 37.377645 GiB/37.377645 GiB object_store_memory, 1.000000/1.000000 CPU_group_0_0cef4fda88e0f3dda0dabb9b54abd0c3, 3.000000/3.000000 CPU_group_0cef4fda88e0f3dda0dabb9b54abd0c3, 3.000000/3.000000 CPU_group_2f27b18ff881043eed191c1135919674, 1.000000/1.000000 CPU_group_0_a158e48561f1ec7f26fb152eeb4699ee, 1.000000/1.000000 CPU_group_1_0cef4fda88e0f3dda0dabb9b54abd0c3, 1.000000/1.000000 CPU_group_2_2c8a52f769e89d5cc7bb50f8b377179f, 3.000000/3.000000 CPU_group_2c8a52f769e89d5cc7bb50f8b377179f, 1.000000/1.000000 CPU_group_2_2f27b18ff881043eed191c1135919674, 1.000000/1.000000 CPU_group_1_2f27b18ff881043eed191c1135919674, 0.000000/3.000000 CPU_group_9903891578ca4945d35c1b3e54f008ea, 1.000000/1.000000 CPU_group_1_37ac7e201c3d77d338995747f50fd7c8, 1.000000/1.000000 node:10.128.0.23, 1.000000/1.000000 CPU_group_2_9903891578ca4945d35c1b3e54f008ea, 1.000000/1.000000 CPU_group_2_0cef4fda88e0f3dda0dabb9b54abd0c3, 1.000000/1.000000 CPU_group_2_a158e48561f1ec7f26fb152eeb4699ee, 0.000000/1.000000 CPU_group_0_9903891578ca4945d35c1b3e54f008ea, 3.000000/3.000000 CPU_group_37ac7e201c3d77d338995747f50fd7c8, 1.000000/1.000000 CPU_group_0_2c8a52f769e89d5cc7bb50f8b377179f, 3.000000/3.000000 CPU_group_a158e48561f1ec7f26fb152eeb4699ee, 1.000000/1.000000 CPU_group_0_2f27b18ff881043eed191c1135919674, 1.000000/1.000000 CPU_group_2_37ac7e201c3d77d338995747f50fd7c8, 1.000000/1.000000 CPU_group_0_37ac7e201c3d77d338995747f50fd7c8, 1.000000/1.000000 CPU_group_1_2c8a52f769e89d5cc7bb50f8b377179f, 1.000000/1.000000 CPU_group_1_a158e48561f1ec7f26fb152eeb4699ee, 1.000000/1.000000 CPU_group_1_9903891578ca4945d35c1b3e54f008ea}\n",
      ". In total there are 0 pending tasks and 5 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:00:16,307\tWARNING util.py:161 -- The `start_trial` operation took 0.925 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 7.0/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (12 PENDING, 23 RUNNING, 15 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=79720)\u001b[0m 2021-05-24 08:00:23,807\tINFO trainable.py:101 -- Trainable.setup took 34.812 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=79731)\u001b[0m 2021-05-24 08:00:23,888\tINFO trainable.py:101 -- Trainable.setup took 34.602 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=79722)\u001b[0m 2021-05-24 08:00:23,910\tINFO trainable.py:101 -- Trainable.setup took 34.807 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=79726)\u001b[0m 2021-05-24 08:00:24,202\tINFO trainable.py:101 -- Trainable.setup took 34.939 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.6/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (9 PENDING, 24 RUNNING, 17 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (9 PENDING, 24 RUNNING, 17 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=582)\u001b[0m 2021-05-24 08:00:36,207\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=596)\u001b[0m 2021-05-24 08:00:36,211\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=602)\u001b[0m 2021-05-24 08:00:36,223\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=611)\u001b[0m 2021-05-24 08:00:36,395\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=612)\u001b[0m 2021-05-24 08:00:36,402\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (7 PENDING, 23 RUNNING, 20 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=33318)\u001b[0m 2021-05-24 08:00:48,543\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=33321)\u001b[0m 2021-05-24 08:00:48,541\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=33327)\u001b[0m 2021-05-24 08:00:48,635\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=33365)\u001b[0m 2021-05-24 08:00:49,823\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=33371)\u001b[0m 2021-05-24 08:00:49,825\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=582)\u001b[0m 2021-05-24 08:00:50,213\tINFO trainable.py:101 -- Trainable.setup took 14.006 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=596)\u001b[0m 2021-05-24 08:00:50,231\tINFO trainable.py:101 -- Trainable.setup took 14.020 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=602)\u001b[0m 2021-05-24 08:00:50,239\tINFO trainable.py:101 -- Trainable.setup took 14.016 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=612)\u001b[0m 2021-05-24 08:00:50,740\tINFO trainable.py:101 -- Trainable.setup took 14.342 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=611)\u001b[0m 2021-05-24 08:00:50,761\tINFO trainable.py:101 -- Trainable.setup took 14.367 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=65571)\u001b[0m 2021-05-24 08:00:56,852\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=65574)\u001b[0m 2021-05-24 08:00:56,854\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=65584)\u001b[0m 2021-05-24 08:00:57,358\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=65571)\u001b[0m 2021-05-24 08:01:10,645\tINFO trainable.py:101 -- Trainable.setup took 13.797 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=65574)\u001b[0m 2021-05-24 08:01:10,663\tINFO trainable.py:101 -- Trainable.setup took 13.812 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=65584)\u001b[0m 2021-05-24 08:01:11,274\tINFO trainable.py:101 -- Trainable.setup took 13.917 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (5 PENDING, 24 RUNNING, 21 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=33321)\u001b[0m 2021-05-24 08:01:18,963\tINFO trainable.py:101 -- Trainable.setup took 30.423 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=33318)\u001b[0m 2021-05-24 08:01:19,060\tINFO trainable.py:101 -- Trainable.setup took 30.517 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=33327)\u001b[0m 2021-05-24 08:01:19,587\tINFO trainable.py:101 -- Trainable.setup took 30.952 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (5 PENDING, 24 RUNNING, 21 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=33365)\u001b[0m 2021-05-24 08:01:31,643\tINFO trainable.py:101 -- Trainable.setup took 41.821 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=33371)\u001b[0m 2021-05-24 08:01:32,038\tINFO trainable.py:101 -- Trainable.setup took 42.216 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (4 PENDING, 23 RUNNING, 23 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.8/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (3 PENDING, 23 RUNNING, 24 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:01,724\tWARNING util.py:161 -- The `start_trial` operation took 0.691 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1946)\u001b[0m 2021-05-24 08:02:05,638\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:05,852\tWARNING util.py:161 -- The `start_trial` operation took 0.744 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 7.2/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (1 PENDING, 24 RUNNING, 25 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:15,027\tWARNING util.py:161 -- The `callbacks.on_trial_result` operation took 0.577 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:15,028\tWARNING util.py:161 -- The `process_trial_result` operation took 0.580 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:15,029\tWARNING util.py:161 -- Processing trial results took 0.580 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:15,029\tWARNING util.py:161 -- The `process_trial` operation took 0.580 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=1946)\u001b[0m 2021-05-24 08:02:15,904\tINFO trainable.py:101 -- Trainable.setup took 10.267 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.5/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (1 PENDING, 24 RUNNING, 25 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=81986)\u001b[0m 2021-05-24 08:02:30,231\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=67043)\u001b[0m 2021-05-24 08:02:32,780\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=67047)\u001b[0m 2021-05-24 08:02:32,778\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (1 PENDING, 24 RUNNING, 25 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.9/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (1 PENDING, 24 RUNNING, 25 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:43,474\tWARNING util.py:161 -- The `callbacks.on_trial_result` operation took 0.715 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:43,475\tWARNING util.py:161 -- The `process_trial_result` operation took 0.717 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:43,475\tWARNING util.py:161 -- Processing trial results took 0.717 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:43,475\tWARNING util.py:161 -- The `process_trial` operation took 0.718 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=67043)\u001b[0m 2021-05-24 08:02:43,775\tINFO trainable.py:101 -- Trainable.setup took 10.997 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=67047)\u001b[0m 2021-05-24 08:02:43,803\tINFO trainable.py:101 -- Trainable.setup took 11.025 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:44,025\tWARNING util.py:161 -- The `callbacks.on_trial_result` operation took 0.546 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:44,027\tWARNING util.py:161 -- The `process_trial_result` operation took 0.548 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:44,027\tWARNING util.py:161 -- Processing trial results took 0.548 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:44,027\tWARNING util.py:161 -- The `process_trial` operation took 0.548 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:44,639\tWARNING util.py:161 -- The `callbacks.on_trial_result` operation took 0.608 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:44,640\tWARNING util.py:161 -- The `process_trial_result` operation took 0.610 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:44,640\tWARNING util.py:161 -- Processing trial results took 0.610 s, which may be a performance bottleneck. Please consider reporting results less frequently to Ray Tune.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:02:44,640\tWARNING util.py:161 -- The `process_trial` operation took 0.611 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 7.1/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (1 PENDING, 24 RUNNING, 25 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=81986)\u001b[0m 2021-05-24 08:03:05,572\tINFO trainable.py:101 -- Trainable.setup took 35.341 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (1 PENDING, 24 RUNNING, 25 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (1 PENDING, 24 RUNNING, 25 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The actor or task with ID fffffffffffffffffba1ddc99f7d189bac39fe9901000000 cannot be scheduled right now. It requires {CPU_group_0_2c8a52f769e89d5cc7bb50f8b377179f: 1.000000}, {CPU_group_2c8a52f769e89d5cc7bb50f8b377179f: 1.000000} for placement, but this node only has remaining {0.000000/18.000000 CPU, 87.214506 GiB/87.214506 GiB memory, 37.377645 GiB/37.377645 GiB object_store_memory, 0.000000/1.000000 CPU_group_0_0cef4fda88e0f3dda0dabb9b54abd0c3, 0.000000/3.000000 CPU_group_0cef4fda88e0f3dda0dabb9b54abd0c3, 0.000000/3.000000 CPU_group_2f27b18ff881043eed191c1135919674, 0.000000/1.000000 CPU_group_0_a158e48561f1ec7f26fb152eeb4699ee, 1.000000/1.000000 CPU_group_1_0cef4fda88e0f3dda0dabb9b54abd0c3, 1.000000/1.000000 CPU_group_2_2c8a52f769e89d5cc7bb50f8b377179f, 3.000000/3.000000 CPU_group_2c8a52f769e89d5cc7bb50f8b377179f, 1.000000/1.000000 CPU_group_2_2f27b18ff881043eed191c1135919674, 1.000000/1.000000 CPU_group_1_2f27b18ff881043eed191c1135919674, 0.000000/3.000000 CPU_group_9903891578ca4945d35c1b3e54f008ea, 1.000000/1.000000 CPU_group_1_37ac7e201c3d77d338995747f50fd7c8, 1.000000/1.000000 node:10.128.0.23, 1.000000/1.000000 CPU_group_2_9903891578ca4945d35c1b3e54f008ea, 1.000000/1.000000 CPU_group_2_0cef4fda88e0f3dda0dabb9b54abd0c3, 1.000000/1.000000 CPU_group_2_a158e48561f1ec7f26fb152eeb4699ee, 0.000000/1.000000 CPU_group_0_9903891578ca4945d35c1b3e54f008ea, 0.000000/3.000000 CPU_group_37ac7e201c3d77d338995747f50fd7c8, 1.000000/1.000000 CPU_group_0_2c8a52f769e89d5cc7bb50f8b377179f, 0.000000/3.000000 CPU_group_a158e48561f1ec7f26fb152eeb4699ee, 0.000000/1.000000 CPU_group_0_2f27b18ff881043eed191c1135919674, 1.000000/1.000000 CPU_group_2_37ac7e201c3d77d338995747f50fd7c8, 0.000000/1.000000 CPU_group_0_37ac7e201c3d77d338995747f50fd7c8, 1.000000/1.000000 CPU_group_1_2c8a52f769e89d5cc7bb50f8b377179f, 1.000000/1.000000 CPU_group_1_a158e48561f1ec7f26fb152eeb4699ee, 1.000000/1.000000 CPU_group_1_9903891578ca4945d35c1b3e54f008ea}\n",
      ". In total there are 0 pending tasks and 1 pending actors on this node. This is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increase the resources available to this Ray cluster. You can ignore this message if this Ray cluster is expected to auto-scale.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (24 RUNNING, 26 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (23 RUNNING, 27 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 6.7/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 57.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (19 RUNNING, 31 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m 2021-05-24 08:04:16,991\tINFO trainer.py:694 -- Current log_level is ERROR. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 5.9/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 57.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (19 RUNNING, 31 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m 2021-05-24 08:04:29,025\tINFO trainable.py:101 -- Trainable.setup took 12.034 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 5.9/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 54.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (18 RUNNING, 32 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 5.4/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 33.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (11 RUNNING, 39 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 4.6/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 21.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (7 RUNNING, 43 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 4.6/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 18.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (6 RUNNING, 44 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 4.1/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 9.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (3 RUNNING, 47 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 4.1/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 6.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (2 RUNNING, 48 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 4.1/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 3.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 4.1/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 3.0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (1 RUNNING, 49 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 4.1/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (50 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Memory usage on this node: 4.1/125.8 GiB\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Resources requested: 0/72 CPUs, 0/0 GPUs, 0.0/339.53 GiB heap, 0.0/149.51 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Result logdir: /lus/scratch/arigazzi/ray_local/PPO\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m Number of trials: 50/50 (50 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m 2021-05-24 08:06:08,388\tERROR worker.py:382 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"python/ray/_raylet.pyx\", line 495, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/actor.py\", line 1001, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/actor.py\", line 1077, in exit_actor\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     raise exit\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m SystemExit: 0\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 95, in updatecache\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     stat = os.stat(fullname)\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'python/ray/_raylet.pyx'\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"python/ray/_raylet.pyx\", line 599, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"python/ray/_raylet.pyx\", line 451, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"python/ray/_raylet.pyx\", line 488, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 167, in format_exc\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 120, in format_exception\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     return list(TracebackException(\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 508, in __init__\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     self.stack = StackSummary.extract(\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 366, in extract\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     f.line\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 288, in line\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 16, in getline\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     lines = getlines(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     return updatecache(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 95, in updatecache\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     stat = os.stat(fullname)\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/worker.py\", line 379, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=3831)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=74649)\u001b[0m 2021-05-24 08:06:08,485\tINFO tune.py:549 -- Total run time: 753.88 seconds (736.33 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f19f8ea9be0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.util.connect(cluster.head_model.address +\":10001\")\n",
    "\n",
    "tune.run(\n",
    "    \"PPO\",\n",
    "    stop={\"episode_reward_max\": 200},\n",
    "    config={\n",
    "        \"framework\": \"torch\",\n",
    "        \"env\": \"CartPole-v0\",\n",
    "        \"num_gpus\": 0,\n",
    "        \"lr\": tune.grid_search(np.linspace (0.001, 0.01, 50).tolist()),\n",
    "        \"log_level\": \"ERROR\",\n",
    "        \"num_cpus_per_worker\": 1,\n",
    "    },\n",
    "    local_dir=\"/lus/scratch/arigazzi/ray_local/\",\n",
    "    verbose=1,\n",
    "    fail_fast=True,\n",
    "    log_to_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4742ce83",
   "metadata": {},
   "source": [
    "## 3. Stop cluster and release allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24151d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if alloc:\n",
    "    slurm.release_allocation(alloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "100a7123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06:39:40 swan SmartSim[1694] INFO Stopping model workers with job name workers-CBLEF8M2VDYD\n",
      "06:39:40 swan SmartSim[1694] DEBUG Process terminated with kill 2252\n",
      "06:39:40 swan SmartSim[1694] INFO Stopping model head with job name head-CBLEF2ZK1XJI\n",
      "06:39:40 swan SmartSim[1694] DEBUG Process terminated with kill 1992\n",
      "06:39:42 swan SmartSim[1694] DEBUG Sleeping, no jobs to monitor\n"
     ]
    }
   ],
   "source": [
    "exp.stop(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020563e8-e6ab-4a0a-9e66-91fd9417a2f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 4.8/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (50 PENDING)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 5.2/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (50 PENDING)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 5.6/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (50 PENDING)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:48:05,917\tWARNING util.py:161 -- The `start_trial` operation took 0.504 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 5.9/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 9.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (47 PENDING, 3 RUNNING)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:48:06,478\tWARNING util.py:161 -- The `start_trial` operation took 0.522 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=24081)\u001b[0m 2021-05-24 05:48:14,554\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24080)\u001b[0m 2021-05-24 05:48:14,633\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=25721)\u001b[0m 2021-05-24 05:48:14,861\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=25724)\u001b[0m 2021-05-24 05:48:14,957\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24494)\u001b[0m 2021-05-24 05:48:15,035\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24085)\u001b[0m 2021-05-24 05:48:15,047\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24498)\u001b[0m 2021-05-24 05:48:15,540\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24499)\u001b[0m 2021-05-24 05:48:15,543\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=33063)\u001b[0m 2021-05-24 05:48:16,141\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=33068)\u001b[0m 2021-05-24 05:48:16,794\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=25801)\u001b[0m 2021-05-24 05:48:18,347\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=25819)\u001b[0m 2021-05-24 05:48:18,324\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=25837)\u001b[0m 2021-05-24 05:48:18,393\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=25855)\u001b[0m 2021-05-24 05:48:18,492\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24154)\u001b[0m 2021-05-24 05:48:18,636\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24197)\u001b[0m 2021-05-24 05:48:19,008\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24215)\u001b[0m 2021-05-24 05:48:19,049\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24611)\u001b[0m 2021-05-24 05:48:19,290\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24593)\u001b[0m 2021-05-24 05:48:19,282\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24629)\u001b[0m 2021-05-24 05:48:19,405\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=33144)\u001b[0m 2021-05-24 05:48:20,201\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=33164)\u001b[0m 2021-05-24 05:48:20,219\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=33203)\u001b[0m 2021-05-24 05:48:20,336\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m 2021-05-24 05:48:20,331\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=24081)\u001b[0m 2021-05-24 05:48:29,079\tINFO trainable.py:101 -- Trainable.setup took 14.526 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24080)\u001b[0m 2021-05-24 05:48:29,147\tINFO trainable.py:101 -- Trainable.setup took 14.519 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=25724)\u001b[0m 2021-05-24 05:48:29,621\tINFO trainable.py:101 -- Trainable.setup took 14.665 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=25721)\u001b[0m 2021-05-24 05:48:29,685\tINFO trainable.py:101 -- Trainable.setup took 14.825 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24085)\u001b[0m 2021-05-24 05:48:29,949\tINFO trainable.py:101 -- Trainable.setup took 14.903 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24494)\u001b[0m 2021-05-24 05:48:29,962\tINFO trainable.py:101 -- Trainable.setup took 14.927 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24498)\u001b[0m 2021-05-24 05:48:30,589\tINFO trainable.py:101 -- Trainable.setup took 15.049 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24499)\u001b[0m 2021-05-24 05:48:30,605\tINFO trainable.py:101 -- Trainable.setup took 15.062 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=25801)\u001b[0m 2021-05-24 05:48:34,107\tINFO trainable.py:101 -- Trainable.setup took 15.760 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=25819)\u001b[0m 2021-05-24 05:48:34,134\tINFO trainable.py:101 -- Trainable.setup took 15.811 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=25837)\u001b[0m 2021-05-24 05:48:34,166\tINFO trainable.py:101 -- Trainable.setup took 15.773 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=25855)\u001b[0m 2021-05-24 05:48:34,287\tINFO trainable.py:101 -- Trainable.setup took 15.797 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24154)\u001b[0m 2021-05-24 05:48:34,366\tINFO trainable.py:101 -- Trainable.setup took 15.730 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24215)\u001b[0m 2021-05-24 05:48:34,522\tINFO trainable.py:101 -- Trainable.setup took 15.473 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24197)\u001b[0m 2021-05-24 05:48:34,638\tINFO trainable.py:101 -- Trainable.setup took 15.631 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24593)\u001b[0m 2021-05-24 05:48:34,998\tINFO trainable.py:101 -- Trainable.setup took 15.719 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24611)\u001b[0m 2021-05-24 05:48:35,120\tINFO trainable.py:101 -- Trainable.setup took 15.834 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24629)\u001b[0m 2021-05-24 05:48:35,490\tINFO trainable.py:101 -- Trainable.setup took 16.085 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=33063)\u001b[0m 2021-05-24 05:48:46,899\tINFO trainable.py:101 -- Trainable.setup took 30.758 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=33068)\u001b[0m 2021-05-24 05:48:49,129\tINFO trainable.py:101 -- Trainable.setup took 32.336 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=33144)\u001b[0m 2021-05-24 05:48:53,756\tINFO trainable.py:101 -- Trainable.setup took 33.555 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=33164)\u001b[0m 2021-05-24 05:48:53,859\tINFO trainable.py:101 -- Trainable.setup took 33.641 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m 2021-05-24 05:48:54,038\tINFO trainable.py:101 -- Trainable.setup took 33.707 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=33203)\u001b[0m 2021-05-24 05:48:54,243\tINFO trainable.py:101 -- Trainable.setup took 33.908 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=24081)\u001b[0m 2021-05-24 05:48:57,364\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24080)\u001b[0m 2021-05-24 05:48:57,528\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=25724)\u001b[0m 2021-05-24 05:48:57,769\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=25721)\u001b[0m 2021-05-24 05:48:57,986\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24085)\u001b[0m 2021-05-24 05:48:58,286\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24494)\u001b[0m 2021-05-24 05:48:58,431\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24498)\u001b[0m 2021-05-24 05:48:58,781\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24499)\u001b[0m 2021-05-24 05:48:58,938\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24154)\u001b[0m 2021-05-24 05:49:02,059\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=25819)\u001b[0m 2021-05-24 05:49:02,105\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24197)\u001b[0m 2021-05-24 05:49:02,209\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24215)\u001b[0m 2021-05-24 05:49:02,240\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=25801)\u001b[0m 2021-05-24 05:49:02,306\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=25837)\u001b[0m 2021-05-24 05:49:02,425\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=25855)\u001b[0m 2021-05-24 05:49:02,459\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24611)\u001b[0m 2021-05-24 05:49:02,853\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24593)\u001b[0m 2021-05-24 05:49:02,914\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=24629)\u001b[0m 2021-05-24 05:49:03,258\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=33063)\u001b[0m 2021-05-24 05:49:19,961\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=33068)\u001b[0m 2021-05-24 05:49:20,591\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=33164)\u001b[0m 2021-05-24 05:49:24,758\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=33144)\u001b[0m 2021-05-24 05:49:24,919\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=33191)\u001b[0m 2021-05-24 05:49:25,157\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=33203)\u001b[0m 2021-05-24 05:49:32,750\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (26 PENDING, 24 RUNNING)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (26 PENDING, 24 RUNNING)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (26 PENDING, 24 RUNNING)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (26 PENDING, 24 RUNNING)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (26 PENDING, 24 RUNNING)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (25 PENDING, 23 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26390)\u001b[0m 2021-05-24 05:51:22,263\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=26393)\u001b[0m 2021-05-24 05:51:22,339\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (24 PENDING, 24 RUNNING, 2 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=26393)\u001b[0m 2021-05-24 05:51:36,163\tINFO trainable.py:101 -- Trainable.setup took 13.825 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=26390)\u001b[0m 2021-05-24 05:51:36,395\tINFO trainable.py:101 -- Trainable.setup took 14.132 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.9/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (23 PENDING, 23 RUNNING, 4 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:51:52,985\tWARNING util.py:161 -- The `start_trial` operation took 0.789 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:51:53,647\tWARNING util.py:161 -- The `start_trial` operation took 0.624 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:51:54,581\tWARNING util.py:161 -- The `start_trial` operation took 0.597 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:51:55,279\tWARNING util.py:161 -- The `start_trial` operation took 0.644 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:51:55,918\tWARNING util.py:161 -- The `start_trial` operation took 0.605 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:51:56,486\tWARNING util.py:161 -- The `start_trial` operation took 0.523 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=26390)\u001b[0m 2021-05-24 05:51:56,780\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=26393)\u001b[0m 2021-05-24 05:51:56,818\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 8.1/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (16 PENDING, 24 RUNNING, 10 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:51:57,292\tWARNING util.py:161 -- The `start_trial` operation took 0.733 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:51:59,591\tWARNING util.py:161 -- The `start_trial` operation took 0.666 s, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.2/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (13 PENDING, 24 RUNNING, 13 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m 2021-05-24 05:52:12,906\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.3/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (12 PENDING, 23 RUNNING, 15 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:52:15,948\tWARNING util.py:161 -- The `start_trial` operation took 0.642 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:52:16,555\tWARNING util.py:161 -- The `start_trial` operation took 0.555 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:52:17,160\tWARNING util.py:161 -- The `start_trial` operation took 0.560 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:52:17,842\tWARNING util.py:161 -- The `start_trial` operation took 0.605 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(pid=28879)\u001b[0m 2021-05-24 05:52:22,434\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=28880)\u001b[0m 2021-05-24 05:52:22,432\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=28881)\u001b[0m 2021-05-24 05:52:22,487\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=28884)\u001b[0m 2021-05-24 05:52:22,572\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=28887)\u001b[0m 2021-05-24 05:52:22,704\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=28888)\u001b[0m 2021-05-24 05:52:22,881\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=27673)\u001b[0m 2021-05-24 05:52:26,923\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=27675)\u001b[0m 2021-05-24 05:52:26,935\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=27679)\u001b[0m 2021-05-24 05:52:27,112\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=27681)\u001b[0m 2021-05-24 05:52:27,116\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=27685)\u001b[0m 2021-05-24 05:52:27,223\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=28881)\u001b[0m 2021-05-24 05:52:38,026\tINFO trainable.py:101 -- Trainable.setup took 15.540 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=28879)\u001b[0m 2021-05-24 05:52:38,105\tINFO trainable.py:101 -- Trainable.setup took 15.671 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=28880)\u001b[0m 2021-05-24 05:52:38,096\tINFO trainable.py:101 -- Trainable.setup took 15.665 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=28884)\u001b[0m 2021-05-24 05:52:38,213\tINFO trainable.py:101 -- Trainable.setup took 15.642 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=28887)\u001b[0m 2021-05-24 05:52:38,200\tINFO trainable.py:101 -- Trainable.setup took 15.498 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=28888)\u001b[0m 2021-05-24 05:52:38,611\tINFO trainable.py:101 -- Trainable.setup took 15.732 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=27673)\u001b[0m 2021-05-24 05:52:41,882\tINFO trainable.py:101 -- Trainable.setup took 14.960 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=27675)\u001b[0m 2021-05-24 05:52:41,906\tINFO trainable.py:101 -- Trainable.setup took 14.972 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=27679)\u001b[0m 2021-05-24 05:52:42,037\tINFO trainable.py:101 -- Trainable.setup took 14.927 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=27681)\u001b[0m 2021-05-24 05:52:42,189\tINFO trainable.py:101 -- Trainable.setup took 15.074 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=27685)\u001b[0m 2021-05-24 05:52:42,217\tINFO trainable.py:101 -- Trainable.setup took 14.995 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=27723)\u001b[0m 2021-05-24 05:52:44,887\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m 2021-05-24 05:52:44,895\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=27725)\u001b[0m 2021-05-24 05:52:44,911\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=27726)\u001b[0m 2021-05-24 05:52:44,909\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m 2021-05-24 05:52:46,180\tINFO trainable.py:101 -- Trainable.setup took 33.274 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (8 PENDING, 24 RUNNING, 18 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=27723)\u001b[0m 2021-05-24 05:52:59,949\tINFO trainable.py:101 -- Trainable.setup took 15.062 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=27725)\u001b[0m 2021-05-24 05:52:59,992\tINFO trainable.py:101 -- Trainable.setup took 15.081 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=27726)\u001b[0m 2021-05-24 05:52:59,853\tINFO trainable.py:101 -- Trainable.setup took 14.945 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m 2021-05-24 05:53:00,062\tINFO trainable.py:101 -- Trainable.setup took 15.167 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=28880)\u001b[0m 2021-05-24 05:53:06,903\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=28881)\u001b[0m 2021-05-24 05:53:07,061\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=28884)\u001b[0m 2021-05-24 05:53:07,015\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=28879)\u001b[0m 2021-05-24 05:53:07,090\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=28887)\u001b[0m 2021-05-24 05:53:07,567\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=28888)\u001b[0m 2021-05-24 05:53:07,555\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27675)\u001b[0m 2021-05-24 05:53:09,072\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27673)\u001b[0m 2021-05-24 05:53:09,125\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27681)\u001b[0m 2021-05-24 05:53:09,205\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27685)\u001b[0m 2021-05-24 05:53:09,153\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27679)\u001b[0m 2021-05-24 05:53:09,226\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=36059)\u001b[0m 2021-05-24 05:53:12,604\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.5/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (8 PENDING, 23 RUNNING, 19 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=27726)\u001b[0m 2021-05-24 05:53:27,299\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27723)\u001b[0m 2021-05-24 05:53:27,466\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27724)\u001b[0m 2021-05-24 05:53:27,492\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=27725)\u001b[0m 2021-05-24 05:53:27,480\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.2/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (5 PENDING, 24 RUNNING, 21 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.1/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (5 PENDING, 23 RUNNING, 22 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.1/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (4 PENDING, 24 RUNNING, 22 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 6.8/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 69.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (4 PENDING, 23 RUNNING, 23 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=28990)\u001b[0m 2021-05-24 05:53:58,361\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=37905)\u001b[0m 2021-05-24 05:54:00,005\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=37909)\u001b[0m 2021-05-24 05:54:00,003\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 6.5/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (3 PENDING, 24 RUNNING, 23 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m 2021-05-24 05:54:00,407\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=28990)\u001b[0m 2021-05-24 05:54:10,023\tINFO trainable.py:101 -- Trainable.setup took 11.662 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.2/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (2 PENDING, 24 RUNNING, 24 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=38040)\u001b[0m 2021-05-24 05:54:12,428\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.9/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (2 PENDING, 24 RUNNING, 24 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=37905)\u001b[0m 2021-05-24 05:54:31,991\tINFO trainable.py:101 -- Trainable.setup took 31.989 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=37909)\u001b[0m 2021-05-24 05:54:31,974\tINFO trainable.py:101 -- Trainable.setup took 31.972 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=28990)\u001b[0m 2021-05-24 05:54:35,947\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=29211)\u001b[0m 2021-05-24 05:54:37,231\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m 2021-05-24 05:54:42,116\tINFO trainable.py:101 -- Trainable.setup took 41.709 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=38040)\u001b[0m 2021-05-24 05:54:42,098\tINFO trainable.py:101 -- Trainable.setup took 29.671 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (2 PENDING, 24 RUNNING, 24 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=29211)\u001b[0m 2021-05-24 05:54:53,741\tINFO trainable.py:101 -- Trainable.setup took 16.511 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=37905)\u001b[0m 2021-05-24 05:55:00,769\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=37909)\u001b[0m 2021-05-24 05:55:00,885\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m 2021-05-24 05:55:10,029\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=38040)\u001b[0m 2021-05-24 05:55:10,091\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=29211)\u001b[0m 2021-05-24 05:55:12,145\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 72.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (24 RUNNING, 26 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.4/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 66.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (22 RUNNING, 28 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31284)\u001b[0m 2021-05-24 05:55:31,935\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=31291)\u001b[0m 2021-05-24 05:55:32,007\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.0/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 63.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (21 RUNNING, 29 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31284)\u001b[0m 2021-05-24 05:55:45,750\tINFO trainable.py:101 -- Trainable.setup took 13.816 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[2m\u001b[36m(pid=31291)\u001b[0m 2021-05-24 05:55:45,800\tINFO trainable.py:101 -- Trainable.setup took 13.793 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.0/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 60.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (20 RUNNING, 30 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.0/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 60.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (20 RUNNING, 30 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.0/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 60.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (20 RUNNING, 30 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31284)\u001b[0m 2021-05-24 05:56:06,436\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=31291)\u001b[0m 2021-05-24 05:56:06,564\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.0/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 57.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (19 RUNNING, 31 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.0/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 36.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (12 RUNNING, 38 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.0/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 21.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (7 RUNNING, 43 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.0/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 21.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (7 RUNNING, 43 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 7.0/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 18.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (6 RUNNING, 44 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 6.6/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 18.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (6 RUNNING, 44 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 6.1/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 12.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (4 RUNNING, 46 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 6.1/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 6.0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (2 RUNNING, 48 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m == Status ==\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Memory usage on this node: 5.7/187.6 GiB\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Using FIFO scheduling algorithm.\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Resources requested: 0/72 CPUs, 0/0 GPUs, 0.0/512.51 GiB heap, 0.0/223.64 GiB objects\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Result logdir: /home/users/arigazzi/ray_results/PPO\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m Number of trials: 50/50 (50 TERMINATED)\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=38507)\u001b[0m 2021-05-24 05:57:29,347\tERROR worker.py:382 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=38507)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=38507)\u001b[0m   File \"python/ray/_raylet.pyx\", line 595, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=38507)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 18, in _disable_client_hook\n",
      "\u001b[2m\u001b[36m(pid=38507)\u001b[0m     def _disable_client_hook():\n",
      "\u001b[2m\u001b[36m(pid=38507)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/worker.py\", line 379, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=38507)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=38507)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=38508)\u001b[0m 2021-05-24 05:57:29,347\tERROR worker.py:382 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=38508)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=38508)\u001b[0m   File \"python/ray/_raylet.pyx\", line 595, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=38508)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 18, in _disable_client_hook\n",
      "\u001b[2m\u001b[36m(pid=38508)\u001b[0m     def _disable_client_hook():\n",
      "\u001b[2m\u001b[36m(pid=38508)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/worker.py\", line 379, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=38508)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=38508)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m 2021-05-24 05:57:29,385\tERROR worker.py:382 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"python/ray/_raylet.pyx\", line 495, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/actor.py\", line 1001, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/actor.py\", line 1077, in exit_actor\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     raise exit\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m SystemExit: 0\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 95, in updatecache\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     stat = os.stat(fullname)\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'python/ray/_raylet.pyx'\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"python/ray/_raylet.pyx\", line 599, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"python/ray/_raylet.pyx\", line 451, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"python/ray/_raylet.pyx\", line 488, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 167, in format_exc\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 120, in format_exception\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     return list(TracebackException(\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 508, in __init__\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     self.stack = StackSummary.extract(\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 366, in extract\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     f.line\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 288, in line\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 16, in getline\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     lines = getlines(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     return updatecache(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 95, in updatecache\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     stat = os.stat(fullname)\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/worker.py\", line 379, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=37918)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:57:29,502\tINFO tune.py:549 -- Total run time: 578.87 seconds (578.48 seconds for the tuning loop).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x2b3f29d4ffa0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tune.run(\n",
    "    \"PPO\",\n",
    "    stop={\"episode_reward_max\": 200},\n",
    "    config={\n",
    "        \"framework\": \"torch\",\n",
    "        \"env\": \"CartPole-v0\",\n",
    "    #    \"num_gpus\": 0,\n",
    "        \"lr\": tune.grid_search(np.linspace (0.001, 0.01, 50).tolist()),\n",
    "    #    \"log_level\": \"ERROR\",\n",
    "    #    \"num_cpus_per_worker\": 1,\n",
    "    },\n",
    "    #local_dir=\"/lus/scratch/arigazzi/ray_local/\",\n",
    "    #verbose=1,\n",
    "    #fail_fast=True,\n",
    "    #log_to_file=True,\n",
    "    reporter = JupyterNotebookReporter(True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4126edb-1c38-4d7e-af30-c39f4d2c9785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31372)\u001b[0m 2021-05-24 05:58:41,433\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=32926)\u001b[0m 2021-05-24 05:58:42,009\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=31372)\u001b[0m 2021-05-24 05:58:48,558\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=32926)\u001b[0m 2021-05-24 05:58:49,178\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=40976)\u001b[0m 2021-05-24 05:58:55,399\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=31101)\u001b[0m 2021-05-24 05:58:55,836\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=31167)\u001b[0m 2021-05-24 05:58:55,834\tINFO trainer.py:694 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=40976)\u001b[0m 2021-05-24 05:59:03,475\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31167)\u001b[0m 2021-05-24 05:59:09,698\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(pid=31101)\u001b[0m 2021-05-24 05:59:09,809\tWARNING deprecation.py:33 -- DeprecationWarning: `SampleBatch.data[..]` has been deprecated. Use `SampleBatch[..]` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m 2021-05-24 05:59:50,120\tERROR worker.py:382 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"python/ray/_raylet.pyx\", line 495, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/actor.py\", line 1001, in __ray_terminate__\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     ray.actor.exit_actor()\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/actor.py\", line 1077, in exit_actor\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     raise exit\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m SystemExit: 0\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 95, in updatecache\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     stat = os.stat(fullname)\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'python/ray/_raylet.pyx'\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"python/ray/_raylet.pyx\", line 599, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"python/ray/_raylet.pyx\", line 451, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"python/ray/_raylet.pyx\", line 488, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"python/ray/includes/libcoreworker.pxi\", line 33, in ray._raylet.ProfileEvent.__exit__\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 167, in format_exc\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     return \"\".join(format_exception(*sys.exc_info(), limit=limit, chain=chain))\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 120, in format_exception\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     return list(TracebackException(\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 508, in __init__\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     self.stack = StackSummary.extract(\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 366, in extract\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     f.line\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/traceback.py\", line 288, in line\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     self._line = linecache.getline(self.filename, self.lineno).strip()\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 16, in getline\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     lines = getlines(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     return updatecache(filename, module_globals)\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/linecache.py\", line 95, in updatecache\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     stat = os.stat(fullname)\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m   File \"/lus/scratch/arigazzi/anaconda3/envs/smartsim/lib/python3.8/site-packages/ray/worker.py\", line 379, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=31125)\u001b[0m SystemExit: 1\n",
      "\u001b[2m\u001b[36m(pid=15462)\u001b[0m 2021-05-24 05:59:50,218\tINFO tune.py:549 -- Total run time: 84.04 seconds (83.26 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    \"PPO\",\n",
    "    stop={\"episode_reward_max\": 200},\n",
    "    config={\n",
    "        \"framework\": \"torch\",\n",
    "        \"env\": \"CartPole-v0\",\n",
    "        \"lr\": tune.grid_search([0.001, 0.002, 0.003, 0.004, 0.005]),\n",
    "    },\n",
    "    progress_reporter = JupyterNotebookReporter(True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e2ebf-7c32-4736-98f7-8fd12a4ce521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smartsim",
   "language": "python",
   "name": "smartsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
