{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4061d9f5-cdfc-4396-bc7d-eaecb9472558",
   "metadata": {},
   "source": [
    "# Online Analysis\n",
    "\n",
    "Being able to visualize and interpret simulation data in real time is\n",
    "invaluable for understanding the behavior of a physical system.\n",
    "\n",
    "SmartSim can be used to stream data from Fortran, C, and C++ simulations\n",
    "to Python where visualization is significantly easier and more interactive.\n",
    "\n",
    "This example shows how to use SmartSim analyze the vorticity field during a simple,\n",
    "Python based Lattice Boltzmann fluid flow simulation.\n",
    "\n",
    "## Lattice Boltzmann Simulation\n",
    "\n",
    "This example was adapted from Philip Mocz's [implementation](https://github.com/pmocz/latticeboltzmann-python)\n",
    "of the lattice Boltzmann method in Python. Since that example is licensed under GPL, so is this example.\n",
    "\n",
    "Philip also wrote a great medium [article](https://medium.com/swlh/create-your-own-lattice-boltzmann-simulation-with-python-8759e8b53b1c) explaining the simulation in detail.\n",
    "\n",
    "<img src=\"https://github.com/CrayLabs/SmartSim/blob/develop/doc/images/latticeboltzmann.png?raw=true\" alt=\"lattice\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d4d45-044e-4c4c-b1e3-1c43a9f87055",
   "metadata": {},
   "source": [
    "## Integrating SmartRedis\n",
    "\n",
    "Typically HPC simulations are written in C, C++, Fortran or other high performance\n",
    "languages. Embedding the SmartRedis client usually involves compiling in the\n",
    "SmartRedis library into the simulation.\n",
    "\n",
    "Because this simulation is written in Python, we can use the SmartRedis\n",
    "Python client to stream data to the database. To make the visualization easier,\n",
    "we use the SmartRedis\n",
    "[Dataset](https://www.craylabs.org/docs/sr_data_structures.html#dataset) object\n",
    "to hold two 2D NumPy arrays. A convenience function is provided to convert\n",
    "the fields into a dataset object.\n",
    "\n",
    "\n",
    "```python\n",
    "    # Select lines from updated simulation code highlighting\n",
    "    # the use of SmartRedis to stream data to another processes\n",
    "\n",
    "    from smartredis import Client, Dataset\n",
    "    client = Client() # Addresses passed to job through SmartSim launch\n",
    "\n",
    "    # send cylinder location only once\n",
    "    client.put_tensor(\"cylinder\", cylinder.astype(np.int8))\n",
    "\n",
    "    for i in range(time_steps):\n",
    "        # send every 5 time_step to reduce memory consumption\n",
    "        if time_step % 5 == 0:\n",
    "            dataset = create_dataset(time_step, ux, uy)\n",
    "            client.put_dataset(dataset)\n",
    "\n",
    "    def create_dataset(time_step, ux, uy):\n",
    "        \"\"\"Create SmartRedis Dataset containing multiple NumPy arrays\n",
    "        to be stored at a single key within the database\"\"\"\n",
    "        dataset = Dataset(f\"data_{time_step}\")\n",
    "        dataset.add_tensor(\"ux\", ux)\n",
    "        dataset.add_tensor(\"uy\", uy)\n",
    "        return dataset\n",
    "```\n",
    "\n",
    "This is all the SmartRedis code needed to stream the simulation data. Note that\n",
    "the client does not need to have an address explicitly stated because we\n",
    "are going to be launching the simulation through SmartSim as shown in the\n",
    "cell below\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea0df6-5fa1-4975-81c9-896157dcba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from smartredis import Client\n",
    "from smartsim import Experiment\n",
    "from vishelpers import plot_lattice_vorticity, plot_lattice_norm, plot_lattice_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b9944-b87c-4e48-9a62-52df744fa83b",
   "metadata": {},
   "source": [
    "## Starting the Experiment\n",
    "\n",
    "SmartSim, the infrastructure library, is used here to launch both the\n",
    "database and the simulation locally, but in separate processes. The example\n",
    "is designed to run on laptops, so the local launcher is used.\n",
    "\n",
    "\n",
    "First the necessary libraries are imported and an `Experiment` instance is created.\n",
    "An `Orchestrator` database reference is intialized and launched \n",
    "to stage data between the simulation and this notebook where we will be\n",
    "performing the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f9c3e-95c9-49ad-b2d4-4fa409aeb36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an Experiment with the local launcher\n",
    "# This will be the name of the output directory that holds\n",
    "# the output from our simulation and SmartSim\n",
    "exp = Experiment(\"finite_volume_simulation\", launcher=\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c45f55-e7a4-4141-a445-85a6158eb12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an Orchestrator database reference,\n",
    "# generate it's output directory, and launch it locally\n",
    "db = exp.create_database(port=6780, interface=\"lo\")\n",
    "exp.generate(db, overwrite=True)\n",
    "exp.start(db)\n",
    "print(f\"Database started at address: {db.get_address()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd9ef13-ae00-4888-b81b-d059736a1c25",
   "metadata": {},
   "source": [
    "## Running the Simulation\n",
    "\n",
    "To run the simulation, `Experiment.create_run_settings` is used to define how the\n",
    "simulation should be executed. These settings are then passed to create a\n",
    "reference to the simulation through a call to `Experiment.create_model()` which\n",
    "can be used to start, monitor, and stop the simulation from this notebook.\n",
    "\n",
    "\n",
    "Once the model is defined it is started by passing the reference to `Experiment.start()`\n",
    "The simulation is started with the `block=False` argument. This runs the simulation\n",
    "in a nonblocking manner so that the data being streamed from the simulation can be\n",
    "analyzed in real time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a1489-b4c3-4736-a628-b7af433a9cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set simulation parameters we can pass as executable arguments\n",
    "time_steps, seed = 3000, 42\n",
    "\n",
    "# create \"run settings\" for the simulation which define how\n",
    "# the simulation will be executed when passed to Experiment.start()\n",
    "settings = exp.create_run_settings(\"python\",\n",
    "                                   exe_args=[\"fv_sim.py\",\n",
    "                                             f\"--seed={seed}\",\n",
    "                                             f\"--steps={time_steps}\"])\n",
    "\n",
    "# Create the Model reference to our simulation and\n",
    "# attach needed files to be copied, configured, or symlinked into\n",
    "# the Model directory at runtime.\n",
    "model = exp.create_model(\"fv_simulation\", settings)\n",
    "model.attach_generator_files(to_copy=\"fv_sim.py\")\n",
    "exp.generate(model, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fad21d-90e4-4d7c-a7a6-4bc84b586c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start simulation without blocking so data can be analyzed in real time\n",
    "exp.start(model, block=False, summary=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc14430-a7e0-4621-a86b-0d7fbd5aa97c",
   "metadata": {},
   "source": [
    "## Online Visualization\n",
    "\n",
    "SmartRedis is used to pull the Datasets stored in the Orchestrator\n",
    "database by the simulation and use matplotlib to plot the results.\n",
    "\n",
    "In this example, we are running the visualization in an interactive manner.\n",
    "If instead we wanted to encapsulate this workflow to deploy on an HPC platform\n",
    "we could have created another `Model` to plot the results and launched\n",
    "in a similar manner to the simulation. Doing so would enable the analysis\n",
    "application to be executed on different resources such as GPU enabled nodes,\n",
    "or distributed across many nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac0fa2-88a4-4c70-a187-764c0c97e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect a SmartRedis client to retrieve data while the\n",
    "# simulation is producing it and storing it within the\n",
    "# orchestrator database\n",
    "client = Client(address=db.get_address()[0], cluster=False)\n",
    "\n",
    "# Get the cylinder location in the mesh\n",
    "client.poll_key(f\"cylinder\", 300, 1000)\n",
    "cylinder = client.get_tensor(\"cylinder\").astype(bool)\n",
    "\n",
    "# plot every 700th timestep\n",
    "for i in range(0, time_steps, 700):\n",
    "    client.poll_dataset(f\"data_{i}\", 300, 1000)\n",
    "    dataset = client.get_dataset(f\"data_{i}\")\n",
    "    ux, uy = dataset.get_tensor(\"ux\"), dataset.get_tensor(\"uy\")\n",
    "\n",
    "    plot_lattice_vorticity(i, ux, uy, cylinder)\n",
    "\n",
    "# Use the Experiment API to wait until the model is finished\n",
    "while not exp.finished(model):\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9999bd1",
   "metadata": {},
   "source": [
    "## Post-processing with TorchScript\n",
    "\n",
    "We can upload [TorchScript functions](https://pytorch.org/docs/1.11/jit.html) to the DB. Tensors which are stored on the DB can be passed as arguments to uploaded functions and the results will be stored on the DB. This makes it possible to perform pre- and post-processing operations on tensors localli, *in the DB*, reducing the number of data transfers.\n",
    "\n",
    "### Uploading a script\n",
    "We can load a file containing TorchScript-compatible functionsto the DB. For example, the file `./probe.py` contains the function `probe_points` which interpolates the values of `ux` and `uy` at some user-provided probe points. This is useful when we are interested in the value of a given fields only at specific locations.\n",
    "\n",
    "The script looks like this:\n",
    "\n",
    "```python\n",
    "def multi_unsqueeze(tensor, axes: List[int]):\n",
    "    for axis in axes:\n",
    "        tensor = torch.unsqueeze(tensor, axis)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "def probe_points(ux, uy, probe_x, probe_y, cylinder):\n",
    "    ux[cylinder>0] = 0.0\n",
    "    uy[cylinder>0] = 0.0\n",
    "    ux = multi_unsqueeze(ux, [0, 0])\n",
    "    uy = multi_unsqueeze(uy, [0, 0])\n",
    "    probe_xy = multi_unsqueeze(torch.stack((probe_x/200 - 1, probe_y/50 - 1), 2), [0])\n",
    "    u_probex = torch.grid_sampler(ux.double(), probe_xy.double(), 0, 0, False).squeeze()\n",
    "    u_probey = torch.grid_sampler(uy.double(), probe_xy.double(), 0, 0, False).squeeze()\n",
    "\n",
    "    return torch.stack((u_probex, u_probey), 2)\n",
    "```\n",
    "\n",
    "Note that we don't have to import `torch`, as the TorchScript interpreter will recognize it as a builtin module.\n",
    "\n",
    "We then proceed to upload the script to the DB under the key `probe` and add the probe points as tensors to the DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_script_from_file(\"probe\", \"./probe.py\", device=\"CPU\")\n",
    "\n",
    "probe_x, probe_y = np.meshgrid(range(20, 400, 20), range(20, 100, 20))\n",
    "client.put_tensor(\"probe_x\", probe_x)\n",
    "client.put_tensor(\"probe_y\", probe_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply the function `probe_points` to the `ux` and `uy` tensors computed in the last time step of the previous simulation. Note that all tensors are already on the DB, thus we can reference them by name. Finally, we download and plot the output (a 2D velocity field), which is stored as `probe_u` on the DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ux_name = f\"{{data_{time_steps-1}}}.ux\"\n",
    "uy_name = f\"{{data_{time_steps-1}}}.uy\"\n",
    "\n",
    "client.run_script(\"probe\", \"probe_points\", inputs=[ux_name, uy_name , \"probe_x\", \"probe_y\", \"cylinder\"], outputs=[\"probe_u\"])\n",
    "\n",
    "probe_u = client.get_tensor(\"probe_u\")\n",
    "plot_lattice_probes(time_steps-1, probe_x, probe_y, probe_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading a function inline\n",
    "In some cases, it makes sense to define the TorchScript function directly in a Python script or in a Jupyter notebook, like in this case. Let us define a simple function which computes the norm of the velocity field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43cc359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_norm(ux: torch.Tensor, uy: torch.Tensor):\n",
    "    return torch.sqrt(ux*ux + uy*uy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then store the function on the DB under the key `norm_function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_function(\"norm_function\", compute_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the key we used identifies a functional unit containing the function itself: this is similar to the key used to store the `probe` script above. When we want to run the function, we just call it with `run_script`, by indicating the `script` key as `\"norm_function\"` and the name of the function itself as `\"compute_norm\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b556de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.get_dataset(f\"data_{time_steps-1}\")\n",
    "client.run_script(\"norm_function\", \"compute_norm\", [f\"{{data_{i}}}.uy\", f\"{{data_{i}}}.ux\"], [\"u\"])\n",
    "u = client.get_tensor(\"u\")\n",
    "\n",
    "plot_lattice_norm(time_steps-1, u, cylinder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbce88c-6f63-407a-8912-5787139f015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally clear the database\n",
    "client.flush_db(db.get_address())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f2669-4efb-4f38-97e9-869a070ab79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminate the database and\n",
    "# release its resources\n",
    "exp.stop(db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bca8a25-6e1b-4540-9d1e-932eb52d7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.get_status(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b42065-6356-4a5a-b742-daca17b8bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.summary(style=\"html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
