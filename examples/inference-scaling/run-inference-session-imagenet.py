import pandas as pd
import os.path as osp
from itertools import product

from smartsim import slurm
from smartsim import Experiment

"""Run an experiment for testing the scaling of the SILC c++ client.
   This script will run as many permutations of CLIENT_NODES and
   CPN (Clients per node) listed in the globals at the top.

   The post processing script collects the statistics generated by
   the inference workloads and combines them into a final CSV saved
   under NAME.csv
"""

# Constants
DB_NODES = 3                 # number of database nodes
DPN = 1                      # number of databases per node
CLIENT_ALLOC = 200           # number of nodes in client alloc
CLIENT_NODES = [10, 20]      # list of node sizes to run clients within client alloc
CPN = [80]                   # clients per node
NAME = "infer-resnet"        # name of experiment directory


# get allocations
add_opts = {
    "ntasks-per-node": DPN,
    "nodelist": "nid00[152-155,196-199,224-231]",
    "mem": "60GB",
    "C": "P100",
    "exclusive": None
}
orc_alloc = slurm.get_slurm_allocation(nodes=DB_NODES, add_opts=add_opts)

client_add_opts = {
    "ntasks-per-node": 96,
    "time": "1:00:00",
    "exclusive": None
}
client_alloc = slurm.get_slurm_allocation(nodes=CLIENT_ALLOC, add_opts=client_add_opts)


exp = Experiment(NAME, launcher="slurm")

def setup_run(nodes, tasks):
    """Construct an MPI program with one SILC client on each rank
    to perform parallel inference.
    """
    run_settings = {
        "nodes": nodes,
        "ntasks-per-node": tasks,
        "executable": "./build/run_resnet_inference",
        "alloc": client_alloc,
    }
    name = "-".join(("infer-sess", str(nodes), str(tasks)))
    model = exp.create_model(name, run_settings)
    model.attach_generator_files(to_copy=["./imagenet", "./process_results.py"])
    exp.generate(model, overwrite=True)
    return model

def start_database():
    """Create a empty database for each run b/c resnet images take up alot of space"""

    db = exp.create_orchestrator(
        port=6780, overwrite=True, db_nodes=DB_NODES, dpn=DPN, alloc=orc_alloc
    )
    exp.generate(db)
    exp.start(db)
    print("DB created and up")
    return db

def setup_post_process(model_path, name):
    """Post Process the results of the inference session
    for analysis.
    """

    run_settings = {
        "executable": "python",
        "exe_args": f"process_results.py --path={model_path} --name={name}",
        "ntasks": 1,
        "alloc": client_alloc,
    }
    pp_name = "-".join(("post", name))
    post_process = exp.create_model(pp_name, run_settings, path=model_path)
    return post_process


def get_stats(data_locations):
    """Obtain inference statistics"""

    all_data = None
    for data_path, name, job_info in data_locations:
        data_path = osp.join(data_path, name + ".csv")
        data = pd.read_csv(data_path)
        data = data.drop("Unnamed: 0", axis=1)

        # add node and task information
        data["nodes"] = job_info[0]
        data["tasks"] = job_info[1]

        if not isinstance(all_data, pd.DataFrame):
            all_data = data
        else:
            all_data = pd.concat([all_data, data])
    return all_data


# run all permutations of nodes and clients per node listed
perms = list(product(CLIENT_NODES, CPN))
data_locations = []
for perm in perms:
    # start a new database
    db = start_database()
    # setup a an instance of the C++ driver and start it
    infer_session = setup_run(*perm)
    exp.start(infer_session, summary=True)

    # get the statistics from the run
    post = setup_post_process(infer_session.path, infer_session.name)
    data_locations.append((infer_session.path, infer_session.name, perm))
    exp.start(post)
    exp.stop(db)

try:
    # get the statistics from post processing
    # and add to the experiment summary
    stats_df = get_stats(data_locations)
    summary_df = exp.summary()
    final_df = pd.merge(summary_df, stats_df, on="Name")

    # save experiment info
    print(final_df)
    final_df.to_csv(NAME + ".csv")

except Exception:
    print("Could not preprocess results")

slurm.release_slurm_allocation(client_alloc)
slurm.release_slurm_allocation(orc_alloc)