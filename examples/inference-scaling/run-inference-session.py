import pandas as pd
import os.path as osp
from itertools import product

from smartsim import slurm
from smartsim import Experiment

"""Run an experiment for testing the scaling of the SILC c++ client.
   This script will run as many permutations of CLIENT_NODES and
   CPN (Clients per node) listed in the globals at the top.

   The post processing script collects the statistics generated by
   the inference workloads and combines them into a final CSV saved
   under NAME.csv
"""

# Constants
DB_NODES = 3              # number of database nodes
DPN = 1                   # number of databases per node
CLIENT_ALLOC = 40         # number of nodes in client alloc
CLIENT_NODES = [20, 40]   # list of node sizes to run clients within client alloc
CPN = [80]                # clients per node
NAME = "infer-scaling"    # name of experiment directory

# get allocations
add_opts = {"ntasks-per-node": DPN}
orc_alloc = slurm.get_slurm_allocation(nodes=DB_NODES, add_opts=add_opts)

client_add_opts = {"ntasks-per-node": 96, "time": "1:00:00"}
client_alloc = slurm.get_slurm_allocation(nodes=CLIENT_ALLOC, add_opts=client_add_opts)

exp = Experiment(NAME, launcher="slurm")


def setup_run(nodes, tasks):
    """Construct an MPI program with one SILC client on each rank
    to perform parallel inference.
    """
    run_settings = {
        "nodes": nodes,
        "ntasks-per-node": tasks,
        "executable": "./build/run_mnist_inference",
        "alloc": client_alloc,
    }
    name = "-".join(("infer-sess", str(nodes), str(tasks)))
    model = exp.create_model(name, run_settings)
    model.attach_generator_files(to_copy=["./mnist_data", "./process_results.py"])
    exp.generate(model)
    return model


def setup_post_process(model_path, name):
    """Post Process the results of the inference session
    for analysis.
    """

    run_settings = {
        "executable": "python",
        "exe_args": f"process_results.py --path={model_path} --name={name}",
        "ntasks": 1,
        "alloc": client_alloc,
    }
    pp_name = "-".join(("post", name))
    post_process = exp.create_model(pp_name, run_settings, path=model_path)
    return post_process


def get_stats(data_locations):
    """Obtain inference statistics"""

    all_data = None
    for data_path, name, job_info in data_locations:
        data_path = osp.join(data_path, name + ".csv")
        data = pd.read_csv(data_path)
        data = data.drop("Unnamed: 0", axis=1)

        # add node and task information
        data["nodes"] = job_info[0]
        data["tasks"] = job_info[1]

        if not isinstance(all_data, pd.DataFrame):
            all_data = data
        else:
            all_data = pd.concat([all_data, data])
    return all_data


# create database
db = exp.create_orchestrator(
    port=6780, overwrite=True, db_nodes=DB_NODES, dpn=DPN, alloc=orc_alloc
)
exp.generate(db)
exp.start(db)
print("DB created and up")

# run all permutations of nodes and clients per node listed
perms = list(product(CLIENT_NODES, CPN))
data_locations = []
for perm in perms:
    infer_session = setup_run(*perm)
    exp.start(infer_session, summary=True)
    post = setup_post_process(infer_session.path, infer_session.name)
    data_locations.append((infer_session.path, infer_session.name, perm))
    exp.start(post)

try:
    # get the statistics from post processing
    # and add to the experiment summary
    stats_df = get_stats(data_locations)
    summary_df = exp.summary()
    final_df = pd.merge(summary_df, stats_df, on="Name")

    # save experiment info
    print(final_df)
    final_df.to_csv(NAME + ".csv")


except Exception:
    print("Could not preprocess results")

# stop the database
exp.stop(db)

slurm.release_slurm_allocation(client_alloc)
slurm.release_slurm_allocation(orc_alloc)